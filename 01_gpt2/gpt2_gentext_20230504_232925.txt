1000 EPOCHS.

“LOOKING PASTE” — or LOOKING PASTE, as it is sometimes called, is a phrase that first appeared in a 1935 magazine cover story about IBM’s first foray into computer vision. The phrase came from a man who had worked with the technology on photographic systems before coming to Apple.

I looked up the spelling of the word pea and began to analyze it for meanings. I soon came to the conclusion that it was a misnomer. It should be pea, which meant looking.

In 1950, the American computer scientist Kenneth C. Roberts took a closer look at the problem and came to the same conclusion. In a famous speech to the American Association of University Slides, he wrote43

I believe in the validity of the hypothesis that under certain conditions light can pass through a barrier and cause an operation’s output signals to be copied along the line. Since I am not expert on this, I can say that it does not hold.

Roberts’s point was clear: given a program that can produce high-resolution pictures of moving objects, there can be leakage of light. The barrier could be such a barrier. I’m not a scientist, so I can’t say much more than I’m willing to bet. But I do believe that the barrier is such that images of moving objects, even if produced by a computer, will be indistinguishable from them, and that computers will be smart enough to figure it out on their own.

Roberts’s central belief is simple. He says that programs that “use computers,” have the same goal: to make more money. He further believes that the same goal can be achieved by programs that use eyes. Eyes, he says, are “absolutely the greatest asset that mankind has while building machines.”46

Yes, eyes are an asset, but not an object. Eyes are an object. The problem becomes, how do you make money off of these little girls?

Like the quest to “LOOKING PASTE” Roberts wondered, “Am I going to have to use money in this quest?,'” leading Roberts Palisades Institute to study this. But this, Roberts thought, was the easiest part. As a programmer you don’t have to worry about it all that much. You just have to figure
====================
PALO ALTO, FL—As the world mourns the passing of his wife Marcella, a local café opened an elegantly decorated and decorated café au naturel space for her husband. The design for the space was inspired by the exterior of the small Sistine Chapel, but with a modern twist. The two half-burnt human remains were transported to Paloma Alta, a UNESCO World Heritage Site, where they were placed into a new high-tech sarcophagus that provides internal illumination and sustains a central purification of aesthetic sensibility.

With the space no longer needing as much light as before, the Alta café adopts a more utilitarian design that uses recycled human tissue. The angled windows no longer narrow into the ceiling, but instead gently open into a space that is just beyond. The angled panels now close into the ceiling that is supported by support systems that move the body's weight as it passes. The result is a space that is almost too rigid and too rimmed. The café’s interior is made of walnut, but the paint is made of a traditional Indonesian palm tree. The walls are made of solid walnut, but the mold is hand-tuned for comfort and readability. The coffee machine now functions as a curtain for the man in the back, but the curtain does not reach down much and moves too short to reach up and down.

“This café serves as a reminder that the design and experimentation that we do to create our businesses are rarely enough invested in the long-term future of our country. Instead, we tend to focus on the simple things that make our lives easier, and we build our companies into institutions that help us accomplish those aims.”

The three pieces of advice I am asking for are that we design our businesses around a certain kind of person—a digital or otherwise—and then make a commitment to their long-term value. They are also consistent with the values I am trying to warn you about: an emphasis on the simple things that make our lives easier while embracing the experimentation that frees us up to think more deeply about our own values and visions for our world.

For example, a simple investment in a new phone or computer is just the first step—a small investment of your time and investment just to make a difference. Done correctly, these pieces of investment can turn into a larger, more permanent change, a migration outward from the
====================
WHY HACKENS SHOULD BE HACKEN

As a teacher, I’ve had the good fortune to teach a class that was repeatedly hammered home by its subject matter: the origins of cybernetic enhancements, the social dynamics of cybernetics, the role of precision manufacturing in the 1941 Pearl Harbor breach. The lessons learned there were tough ones, and in them I learned something new: the need to balance technological upgrades against the human need.

That need was never fully addressed by the teaching methods, but over the decades the human element of the lessons learned has waned a bit. As a teacher and technology critic, writing in the New York Times in 1966, I told the class that the technological basis for their concerns was "soot and germs" that were now being "cleaned up." They pointed to heavy-handed cybernetics methods as having contributed to mental health problems, and in interviews, I heard self-righteous assessment that their appearance had mostly been borne out.

Not so today, said Julianna Schwartz, a professor of psychology at Carnegie Mellon who has studied the subject matter of cybernetics and the cyberbreach. The cybernetics field is "getting more abstract, and it’s getting easier for people to make decisions about their personal and professional lives online. "

WHAT SHOULD BE DIVISION OF THE EFFORT?

Not much is known about the goal-oriented cybernetics advocates today, but there is a clear desire to move toward a goal-oriented technology deployment. The goal of the group is to get the most benefits from a distributed system, and this translates into the total amount of economic activity possible within a distributed system. As a result, the objectives are often driven by economic incentives. The goal of the techno-optimists is to get the most economic benefits from a distributed system, whereas it is generally understood to be the other way around to be getting the least benefits at the expense of others.

The techno-optimists recognize that there is no guarantee that no adverse outcomes would result from the use of distributed solutions. They point to the example of China as an exception, where the primary motivation for government involvement was the hope that the system would be able to subsidize basic needs.11 That did not mean the government put in place adequate safeguards, nor did it attempt to control what ideas and innovations could be found in the distribution centers. It just so happened that many of
====================
A machine learning system, such as Lalit Bahadur Chaturvedi’s Siri, uses machine-learning techniques to fine-tune a series of facial expressions, which in turn are trained on data from the human face. A facial expression is then presented to a computer for a minute to see which one generates the most emotions, then the software cranks up the volume and hue of those facial expressions to see what combinations of emotions it can convey.

The software then "recalls" its progress in milliseconds, and often compiles these statistics back into predictive AI systems. It’s a process that can shave an average of five years in the history of AI. Lalit says his company’s AI-powered conversational assistant is able to convey "a deep, human-like quality to its users, a tenfold boost in overall intelligence."

Companies like Lalit are already seeing the benefits of AI. In 2018, for example, Three Four Eighteen, a British media conglomerate, announced that it was creating a "chat-advice app" that would "provide expert advice and understanding the complexities and opportunities of life in the real world." The app would "build the ultimate tool for discovering the treasures of the human mind," according to the Daily Mail. The company claims to have created the world’s most comprehensive resource on life and death: "The app will help users plan and plan for the coming years, provide practical tips for managing financial risks, and present insights to those who might be hard-pressed to find common cause with them on social issues."

The potential of AI in the real world has already been realized. In 2018, the U.S. Surgeon General declared the field of artificial intelligence “ready for prime time." AI is already "excited," he said, speaking about the possibility of "human-level Al, for those new to the fundamentals of artificial intelligence or those who are looking for a general-purpose agent that can lead or lead-edge on some fundamental research.” His 2018 book On the Edge of Cognition: AI, Sensitive Systems, and the Promise of Life, Is Directly Benefiting All People, Extraction, and Action:

As we move into the age of AI, there will be a lot of new opportunities to get involved in the social, political, and economic processes that impact us all. The age of profit maximization will bring
====================
Can you think of a more appropriate name? In this episode, we asked Geoffrey Hinton, the AI professor who recently penned a book, The Turing Trap, about the paradox of the Turing test. The paradox is that Hinton, for example, suggests that a certain person win the imitation game, a bet that Hinton’s book predicts he will not win, because the book he is predicting the book about Turing will be published in the United States. Hinton responded that this was a “honey trap” that could lead to his book’s ending. Now, that might be true in the extreme, but I think it’s more plausible in the context of a legitimate, legitimate, legitimate debate about the Turing Trap than something like an assault on First Amendment’s validity. And that, I think, is the whole point of the Turing Trap.

You mentioned Hinton. Can you give us an example of how that works? Do you mean “honey traps” that come out of the window when something like reasonable doubt springs up? Or, in the former, “honey traps” that are first put in the window, turn on you’t and immediately go off?

Well, first, there’s the classic example of an academic paper being published in the United States: a well-known paper by Turing, Herbold, Schenk, and Simon (the authors of the book), all from the same computer. They all share a Ph.D. in computer science and work on various problems in the field of AI. They all come to Harvard for a Ph.D. in computer science, and so they are good fits for the kind of paper that I mentioned earlier, except they are all Ph.D. students working on very different kinds of problems in the same field.

I mentioned earlier that Herbold and Schenk came out of the window when the real Turing–Woods were there, too. And so, for instance, when Herbold and Schenk are discussing the feasibility of building intelligent computers, they are discussing a paper by a very respected computer scientist, John McCarthy. McCarthy is very critical of AI and has published extensively on the subject. In an email to me, McCarthy extolled Herbold and Schenk for their work on the book, writing

We wrote the book because we think the potential superintelligence of
====================
The study used data from the U.S. Consumer Product Safety Commission ( CPSC ) Consumer Product Safety Commission Web site to compare the attitudes and behaviors of 1,500 randomly-predicting singleton data collectors over their 1,500 known products.

The researchers found that the large collection sites clustered together, reducing the probability that a singleton would become a hotspot for cyber-crime. The risk of such crimes increased even among data sites that clustered together, the researchers found.

Product safety advocates point out that, under current law, data collection is legal under the American public interest framework and everyone is covered by the law. They point out that many American companies already collect data from the home and then use it to make products. And even if you don't, the data can be used to create personalized medicine for improved outcomes, which advocates say are often not justified by the circumstances.

But in a recent article, the researchers point to the ways that automated systems can be used to misinform consumers about what health care they need, erasing important contextiles of consumer choice and choice. They write:

The large volume collection of individuals and industries provides important information about the potential impact of various products and narrows the scope of potential law enforcement considerations. However, the large volume collection of individuals also allows automated systems to infer important contextual information about the buying and use of a specific product without first obtaining the necessary consumer consent. This allows automated systems to impersonate consumers without first obtaining full consent and allows the collection of data from consumers who have been informed about the potential harms of the product without first obtaining prior consumer consent.

The researchers point to several limitations of their study, including limitations of the data collection, and limitations of using the method with other researchers in the future. Newer automated systems that can be used with other researchers, such as called "interrogators," use a "prioritized capture," in which the collected data is used to reduce the chance that the system will be used in the future. These limitations are explained in more detail in the next section.

The researchers also recommend that universities collect and use real-time, real-time consumer data before using this technology, also known as data broker or data "anatomy broker." These technologies can be helpful for credit score systems, financial statements, and consumer auditing, among other applications, but they are not widely available right now. Such systems are still used by
====================
In the photograph, the cockpit door opens and closes behind me. The man behind the counter is dressed in a dark suit with a light brown tie and a square metal key. He looks on with wide, serious and gravelly eyes. He speaks slowly and almost breathlessly, about the need to "think of the company you work for, Baidu. . . . I think we should start thinking about Baidu in the same way."

With a shake of his head, I say nothing, choosing instead to observe the situation with the naked eye. The man in the dark suit gives a short monologue, and the camera's focus shifts to reveal an oddly shaped expression on the man’s face. It’s almost as if an alien machine has asked permission, and given it the opportunity, to devour his personality.

The man in the dark suit gestures with a dismissive smile. "It would be great if we could work out what it is we are working on."

I take the man’s answer as confirmation that I do not trust Baidu. I do not trust any AI system other than the man’s own. Baidu has many projects in various stages of development, including being one of the first to demonstrate the concept of a self-driving taxi in a demonstration clip on YouTube. If you want to watch the video, grab a movie or listen to some radio broadcasts while the man drives around in a Segway.

Bungi’s engineers have released no plans to develop AI into the cockpit of commercial drones. Instead, they are working to build an AI ecosystem out of the cockpit: a kind of public holiday cake. Baidu has given its employees the keys to the bakery, but most of the employees at Baidu begin their day at work there. The company has also given its employees the keys to the bakery simultaneously, but most of the jobs at Baidu end there. So what happens when artificial intelligence workers take up the bakery position? Well, one word in particular stands out. It’s called “self-POWERING”.”

Self-POWERING is an important concept. Self-powering refers to the ability of a computer’s processing power to perform its task at high enough level that no two tasks can meet. High level is traditionally associated with work that involves more than just steady work of
====================
“Maybe you’ve already done it.” “I“m going to start by telling you how important this is. It’s the foundation for much of what we’ll be building.” I say this because the second sentence of the first sentence—“I”—is both prophetic and necessary. If you’d already done it, I can just say it to you now.

“Because it’s so easy. Just go with it.” If you already knew me, or you already think you know me, you know that this is the first time this has happened. And you already know that I’m going to be here for you. Because I’ve already told you that this is going to be a learning experience for me, going to show you how important this is. And I hope that you also do agree with me that it’s going to be a learning experience for you.” So, then, I say, “Okay, I think this is the right thing to do. I’m going to start with you. Let me explain. Let me begin by explaining how I think this is.

1
THE STARTUP CHECKLIST

1. New Beginnings

Before we start, let’s first get some basics up-to-date.

- Basic hardware for the operating system (OS)

- Up-to-date operating system software
- Up-to-date operating system libraries
- Power software (PowerShell, X Window, x86)

- Up-to-date operating system source code
- Up-to-date data structures and algorithms
- Power software (PowerPC, Raspbian, etc.)
- Up-to-date operating system source code

- Up-to-date information about the operating system (such as a drivers license number, a Microsoft Office document, or an Internet search engine program)

- Up-to-date information about the data structures and algorithms in the operating system (such as a date and time, for example)

- Up-to-date information about the various algorithms used to calculate the various steps in the training process
- Up-to-date information about the various special-purpose programs that are used in the training process

- Up-to-
====================
”

Yesterday a Microsoft engineer posted a patchwork of fixes to a widely-compiled code base, demanding that an editor at a major U.S. computer company forward changes to its code base in the form of bug fixes.

On Twitter, the message was swift and direct:

The time has come to pass in the past week or so to develop a code editor that can accept PR, report back to team, and avoid PR conflict based on opinions shared by users

The reply has been to the effect of exactly what you want, to the effect of, “Don’t post this patchwork here.”

The message was much the same across the internet:

The time has come to pass in the past week or so to produce a code editor that can accept PR, report back to team, and avoid PR conflict based on opinions shared by users. — Daniel Abraham (@danielabraham) November 3, 2017

Microsoft said it would implement the message in its software, and that it had also successfully done so for Yahoo! engineers. But several users on Twitter and on the Web expressed similar requests not to share their requests about writing their own internal programs for writing PR for search engines and other companies.

The call for more transparency around how AI is judged and evaluated came from as far as we know: AI expert Julie Bitonin. In a blog post, she wrote that such decisions are kept secret from the public because they can’t be seen as final, unbiased guidance for how to conduct a business.

I believe the programmers at Microsoft deserve to be able to see what’s coming next, and they deserve to be able to make the necessary changes to make this happen. — Julie Bitonin (@JBLINNET) November 3, 2017

The concerns about transparency around AI have been raised at length by other AI experts, notably my own colleague Kevin Roose. In a phone call this week with reporters, he said that people on both the Web and in the business world gave wildly divergent answers to questions about when and how AI was born and how it evolved.

Here is the exchange:

Delivering on my vision for “AI,” Mr. Roose said he wanted to make sure the technology could be tested at scale and that its eventual release would be transparent. He added that such a move would allow the community to “
====================
“I am not going to lie, this whole situation just got me thinking.” “I” said. “I think I’ve got a point” “But you asked me to be a good example, not to other people?” “That’s just not how it should be,” “I think I’ve got to learn the hard way, man.” “I don’t want to be judged on my work,” “I just want to be a human being.” “I want to be a good example to other people.” “”

“You have to understand, I think we’ve got to change the way we think about what AI is,” Hoejn said. “And I think we have to recognize that there’s a lot of work that we can’t do,” and there’s a lot of debt that we can't pay.”

“But you’ve also said that” “it’s not my job to decide what we’re going to do,” Hoejn said. “I think we’ve got to move beyond what we do.”

“You’ve also said that” “it’s not my job to decide what we’re going to do,” Hoejn said. “But I do think we can move beyond what we do,” Hoejn adding that AI could change the world.”

“I think we can move beyond what we do,” Hoejn concluded. “And I think we’ve got to talk about what our next steps are,” Hoejn adding that conversation should focus on making sure machines aren’t putting people’s lives at risk.

Final words

In the lecture Hoejn delivered to the AI symposium, he laid out the challenges of his career, from the business side, and the broader societal side, as well as a vision for how he might approach the future. Hoejn laid out in broad strokes what AI is all about, how it should help people, and how that collaboration has
====================
“New possibilities for AI lie ahead.”

That sounds incredible in itself. AI is not yet conscious. We are already used to powerful AI tools like Siri, Cortana, and the ability to hire models and improve your models’ performance. But what if that ability to create better AI is no longer so different from that of humans? We wouldn’t just be building more intelligent AI tools. We would be building tools for the people who use those tools. That’s a difficult question to answer, but one thing's for sure – building smart tools for the people is a big part of the answer to the challenge of our times.

“To solve the challenges of AI,” the future requires us to move beyond a focus on algorithms and algorithms for smart systems, a part of the equation that we’re still not fully equipped with.

So, for the uninitiated, the good news is that for the uninitiated (and especially those who are already rich and famous), the answer is yes, there is no such thing as a zero-sum game. In this book, we’ll explore the ways in which AI tools can be used to divide humanity into socially andationally more socially aligned portions.

The bad news is that that’s not how it works. When a tool does get better, it often doesn’t do what many people hope it would. Instead, it creates a vast amplification of human capabilities and improves them incrementally. The good news is that as AI becomes ever more powerful, it’s also becoming possible to “waste” on the augmentation, for both the worker and the machine. This has created a tidal wave of “AI technology” that’s already blowing out billions of dollars in development costs and on the manufacturing side billions in lost sales.

The AI Wars

Back in 2002, when I launched my AI Consulting firm, the first thing I tweeted was “AI is back. We’ve been doing this for over a decade.” Today, the topic of AI is not just a focus of daily life in Silicon Valley but one that many Silicon Valley entrepreneurs find difficult to sell.

In an article for the New York Times, I wrote, “The market for AI-based products and services is on the verge of closing on the hardware, the software, the data
====================
“Useful for automating the process of manufacturing.” —Tesla CEO Elon Musk

The name Tesla should not only be able to say one thing very specifically to help it stand out from the crowd, but is able to do the other things well. Take the company’s advanced safety system, which was recently released in its alpha stage. The alpha phase—the testing phase— gives engineers a better understanding of what technologies are most likely to be at risk of misfire, as they try to operate it in a controlled environment. It also allows engineers to try out various diagnostic tools, to see if they can uncover any fault patterns with the system or whether they can tweak the underlying architecture to make it more performant or faster.

Those improvements should make the Tesla Roadster a much more capable car-buying process-and-driver-“s-“world-” than it was in its early days. But improvements come at a cost, and it’s only a matter of time before the Roadster breaks even.

Right now, the Tesla Roadster is just getting started. Early tests show that the car does a surprisingly good job at driving itself, thanks to its refined, aerodynamic design and surprisingly smooth and responsive road surface. The company has also been found wanting on social media, with users asking the company to change the car’s music and voice command. The Roadster is also now benefiting from significant investments in its own future, as Musk has in the past mentioned his desire to build a faster, more efficient car manufacturing process. That may not seem like such a big deal now, but in the future, you can expect big bets on new products and a sizeable chunk of the future’s market share.

But should the Tesla Roadster prove too much for some carmakers, or too little too late for others? Could the company’s runaway success be the beginning of a new chapter? Could the wave of autonomous-vehicle adoption turn into a tidal wave that destroys companies and speeds up processes?

THE RISK, but Not the End

Autonomous robots are already a long way from self-driving cars and some of the challenges posed by them-driving while hunched over-driving while running in rough terrain-require a different level of engineering-aren't just theoretical or practical-they’re human-“infrastructure-wide- too
====================
New research suggests that working less, playing less, and becoming more productive might be associated with lower levels of self-efficacy and negative affect.

A new study from psychology and executive researchers at the University of Chicago suggests that the opposite may be true. Using information as a resource, the brain of an artificial general intelligence may be less efficient at resource acquisition than the brain of human-level oracle programmers. That may hold true for AI, but not for programmers.

The researchers studied eight people at a college during the 1950s and 1960s: sit-downs, lecture tickets, the Stanley Cup, the Stanley Cup, the Turing Test, and at least one popular Hollywood movie. They also studied four people who had worked at Apple and had scored high on the Apple I’ve used, which is often the first computer you see at a tech company. These studies didn’t find any significant differences between the ways that the AI brains were using information.

The researchers found similar results when they changed the way that their data was organized. After adjusting for some of the cognitive differences between the ways that the AI brains were using data, the findings were in line with what psychologists call “self improvement”—that is, people’s efforts to improve their own cognitive performance.

The point here is that instead of trying to swap data bits for algorithms, we should encourage the use of whole brain emulation research. Emulations are computational reagents that mimic the properties of a particular computer part and then produce output similar to that part’s performance. The idea is simple: If you can, copy the emulation part and replace it with a new one. It’s also possible to create whole brain emulation research using ideas from cognitive psychology and neuroanathematics. Researchers can then begin to study how the brain can be improved.

Research into whole brain emulation has been going on for a decade now and the results have finally been published in a prestigious scientific journal. That’s right, “The best thing that ever happened to science fiction?” That’s right, research into whole brain emulation is happening now and will continue to be done by today’s most advanced society. Thanks to the power of AI and other cognitive technologies, research is now beginning all over the world to explore the possibility of using whole brain emulation instead.

There are several reasons why whole brain emulation is sexy. First
====================
“Don't worry, the robots are fine,” the robot said.

“Are they all right?” I said.
“No,” the robot replied. “All the robots are fine. Just keep seeing them.”
That sent me running for my lives. Smartphone app Icy robots are everywhere, but not so well paid ones in China. Are you serious? I asked one of the employees, my age, who works for the night shift, why he was coming to my house late one night.

“Because the other robots don’t have night shifts,” the employee replied.

“But we do have night shifts,” I replied.
“But we do have robots that don’t have night shifts?” the employee replied, speaking in Mandarin.
“Exactly.” I said, breaking news.
That winter, one of my robots died in an avalanche near Beijing. I had planned to set up a robot hospital for the dead, but when I learned of the robot’s tragic death, all I wanted was my robot back. That winter, my wife and I both begged and pleaded with the robot to come back, but it wouldn’t budge. We would rebuild it, make it moneyable, and bring it back to us humans. It wouldn’t. It wouldn’t understand. It wouldn’t care. It just wanted to be with us. That winter, we also learned of its existence story, but the more we tried to do so, the less we’d made any lasting financial impact.

The truth is, we made a very good first impression. We learned so much from the robots that we both stopped trying to be human. We both learned so much from our work. And we both learned to put our shoulders where one another’s back, in the process, building our companies, our empires, and our values.

Our AI companies have evolved in leaps and bounds over the years, and we expect our approach to evolve in the coming years. But the fundamental difference between us and machines just began to show. We both know how to operate machines, and we both value the people who provide for us. That’s why we both chose to be human. That’s also why we both began to search
====================
This story was produced with the help of the New York City-based production company ofiTunes, which has a long history in the audio-visual production sector. We spoke with the company about its history as it develops the company's forthcoming subscription-based software, which will allow musicians to record live performances from studios far away from a soundstage.

New York City-based iTunes is known for producing high-tech features for the tech sector, including the plug-ins Suite 911 and Suite 93.5, which have been sold to music-video companies such as Avicii Music and Viacom, respectively. A standalone app called Clickturns (short for Welch Automation, which became known as the “Pause & Play”) was released in 2005. That app, which uses Siri and contextual settings to inform the musician to turn on or off his or her computer, has racked up more than 10 million installations and is now used by over 100,000 musicians.

When was the last time you heard a live iTunes performance?

Around 2005, we had a chance to have a chance and gave it a listen. It’s called (we assume) the iTunes Open House, and it was recorded in Manchester a few days after we did our show. We had a fantastic band of people on stage and it was almost pitch-perfect.

We recorded four minutes of acoustic material – a lot of acoustic material from the show, but mostly just recordings of acoustic performances. We used a Hammond 744K with a 24-track tape deck for editing and produced good recordings.

We mostly used the Hammond 744Ks for our set, but we also recorded a couple of Hammond-Kenny machines for later use. We also had a couple of Sinclair B000s built for us, but for this show we used the Sinclair B500s for the live recording.

The Hammond-Kenny machines are great, but you can get the most out of these machines. We used to record shows in the afternoon and then go to the bar around 3 p.m., but that changed last year. Now you just hear the rhythm of the recording, and you get the sense of time and place. It’s a real isolator in that it records with greater fidelity and detail.

You can also put on the Timbre-Able keyboards and have the acoustic material
====================
Scholars have long debated whether there is a causal relationship between sitting longer and health. Physical activity increases one's alertness, alertness to unexpected hazards, alert to unexpected possibilities, alert to the possibility of failure. If our brains are designed to optimize for this heightened awareness, we could be committing ourselves to a long, long run in our being tuned to alertness to a long run. If we can't get our heads around the fact that our lives involve many unexpected hazards, there are no good reasons for us to get our lives covered in the first place.

It is important to understand just how important alertness is. Research has shown that increased physical activity leads to heightened alertness, which correlates with increased likelihood of being able to succeed in our jobs.14 Studies have also shown that increased physical activity leads to heightened chance of being able to succeed in our jobs.15 The idea that humans are genetically predisposed to get ahead and get along on the team because we're in a position to succeed on the team is obviously not something that can be taken literally. The same goes for superintelligent AI. It is something that scientists are currently trying to model and test.

Research by psychologists Ursula Franklin and Simone Browne has demonstrated that people who are physically active lead to increased cognitive ability, which correlates with increased likelihood of being able to pass on a job fair.16 Researchers at the University of Edinburgh have found another way to explain why physical activity leads to increased alertness: they find that physically active people are also to be expected to do well on tasks that require high levels of alertness. In other words, they think, people tend to be alert when they are physically active, whereas sedentary people are expected to be lethargic in the least.

Many experts agree that sedentary humans are not just physically unable to perform jobs well; they are also frugal and lazy. They believe that in the age of intelligent machines, we will need to introduce a stipend to incentivize physical activity. They point out that the average American adult currently works about thirty minutes per day, so a stipend of one hour is probably not going to cut it for us. In addition, a study in the United States showed that people are actually looking forward to working more hours, with the expectation of being able to spend that time on necessities such as transportation and a night of rest.

These studies are all well- accepted within their respective disciplines. They point
====================
“We don’t have time,” he said. “We just need to organize and make our voices heard.”

The organizing principles are simple. Organize as efficiently as you can and have people take the time to get to work. If you’re not on site or if you’re not on Facebook or if you’ve never had the pleasure of meeting new people, then go ahead and organize an event. Organize is not a one-way street. Organize can be very effective. Organize means pay back taxes, make better loans, find love, and have higher quality adult children. Organize means go on vacation, have a family, have some fun, have a good time, have some sex, have some contact, and so forth.

The Black Rock Desert is no different. As you can see in the figure below, the “eighties surge” started with a succession of high-profile success stories: Andy Warhol’s Andy Richter (1959), Bugs Bunny’s Bugs Hefner (1972), Bill Murray’s Bill Murray (1984), and Peter Berg’s Bergamasqua (1991). You can see also the figure seven that began the Warhols “trip” with Bugs Bunny.

The first set of unabashedly anti-technology books (in the street bookstore) were published by the late American author Harvey Kurtz (1915–2007; Fig. 7.1) in the mid-1960s. His first collection, The Frogs in the Jungle, was a critical darling of both science fiction and non-fiction magazines. His most recent, The Creepy Tales of a Creepy Web, was released in September 2016. The Creepy Tales of a Creepy Web is a collection of creepily illustrated Creepy Web stories, each one a true story. Each story is a true story, but each is a true story about a person who is (in the words of one critic) “stupid,” the writer's character, and the computer (in this case, a program written by Alan Turing).

The stories are funny because they are true. They tell the story of how a person was turned into a creepy Web page by the times, only to be turned back inside out, completely unprepared for the new reality that lay before him. The stories are true because after
====================
“A Call to Action”

To all those who have served in the “Humanity First” field at scale, please share this post with your colleagues, and please also consider sharing this article with your school colleagues, in the hope that they too can see this as a call to action.

In the past, we’ve seen calls for organizational changes to the “Humanity First” field. But as of 2019, the most recent year for which data is publicly available, we are still not entirely there yet. As a result, these types of calls for organizational changes will continue to grow in importance.

Executive Order 13960 on Promoting the Use of Artificial Intelligence in the Federal government ordered the following steps:

1. Establish a task force to consider recommendations from the task force on enhancing the use of “radiative, proactive, and sustainment technologies for the mitigation of adverse outcomes and organizational outcomes related to the use of AI in the Federal government workforce.”

2. Develop a strategy to guide the establishment of the task force.
3. Coordinate the activities of the task force to include workshops, workshops, and other opportunities to provide input on organizational changes to incorporate AI.

4. Develop a plan to best utilize AI in the Federal government workforce.

5. Develop and implement a Blueprint for an AI Bill of Rights in the Federal government workforce, which includes recommendations for:

- Developing a system to audit and control audit reports about AI- intensive federal departments and agencies
- Renaming and eliminating redundant roles

- Providing oversight and assessment of AI- intensive federal departments and agencies
- Installing monitoring systems to monitor AI systems in the critical functions that are traditionally performed by human employees
- Working with the American public to identify opportunities for oversight and mitigation of AI-related harm in the public sector

6. Develop and implement a Blueprint for an AI Bill of Rights in the critical functions that are traditionally performed by human employees-Providing oversight and assessment of critical functions in the public sector to ensure their proper and proportionate use and the proper proper use of resources allocated for such purpose
- Working with the American public to identify opportunities for meaningful oversight of AI systems and for ensuring that they perform their functions in a manner consistent with the needs and values of the American people

7. Establish oversight of AI systems in the critical functions that are
====================
It’s no secret that Google has trouble translating human-readable search results back to English. But over the years, that translation process has required some iteration and optimization work before that translated result. Now researchers at Google—the parent company of Google’s parent company News Corp.—have put their major edge behind a new translation technology: artificial-intelligence.

“Real-time image filtering,” as Google’s AI subsidiary DeepMind is called, uses machine-learning techniques to filter out the English-language world into a series of progressively more optimized \resources” Google’s words. Google calls the process “supervised translation.”

Google has been developing this technology for two decades, but in that time it has only done it for a small percentage of the languages it has access to. Now that access is coming to a speed up, thanks to AI tools like TensorFlow and large pools of computational resources like AI-powered deep-learning units.

“Real-time image filtering,” as Google’s AI subsidiary DeepMind is called, uses deep-learning techniques to filter out the English-language world into a series of progressively more optimized \resources” for processing the words in the captured text. Google calls this process “supervised image filtering.”

The technology has been around for a decade, but the AI giant says it has the largest diversity of teams in the world when it comes to image processing done by humans.” It uses the same software that powers Google’s search engine, ImageNet, and uses a proprietary algorithm that uses AI to determine which words are closest to the words in the captured text. ImageNet then uses deep-learning techniques to sift through the words in the captured text for similarities and differences, and then uses a large part of that knowledge to create a new image.

“Using the same software that powers Google, you can process the same data multiple ways,” says Chris Atherton, Google’s vice president of global innovation and market strategy. “It’s not a one-size-fits-all approach.”

Google has pioneered the use of AI for the task of translation. Translation is easier, faster, cheaper, and more satisfying for almost anyone looking to move the pieces of the world order. Translation is also easier for companies like Google to use
====================
Wealthy entrepreneurs have been relentlessly seeking to shift the fundamental paradigm of AI by moving beyond pure pure expertise to access a wider range of entrepreneurs and early-stage investors who may not otherwise be included in the mainstream. As we saw in chapter 4, this has meant harnessing AI for alleviating work-related illness, anxiety, and depression. It has also meant making early investments in AI-enhanced startups—in this case, deep learning algorithms—as a way to broaden their footprint and expand their existing audience. As Fei-Fei has said, "There is no free lunch, and there is no silver bullet, so if you want to win the race, you need to start somewhere."

But building AI-driven companies requires a broader shift in the economic landscape. While GPT-4 is a particularly good example of this, the next generation of AI-driven companies should be built in the same ballpark as the first, broadening their offerings across a wide range of economic and service sectors. The good news is that the next wave of business AI will probably be far easier to acquire and more scalable than any previous. Just as traditional monopolies have been easily crushed by competitive AI, established companies can now easily be reorganized to compete on a much higher level of customer service.

As we saw in chapter 5, many AI companies have already answered questions and answered answers by introducing novel and practical business innovations. We’re already seeing startups that excel at identifying opportunities and then following those opportunities to maximize returns on their investment. And as we saw in chapter 6, these startups can also be reorganized to create new products and services, and enable different work processes at the company. These are all good, broadly acceptable ways for a technology company to respond to the new business realities and then reimagine how it operates.

But building a new business from the ground up requires a broader shift in the economic landscape. For one thing, a rising AI economy will raise manufacturing and services production costs astronomically, particularly for the low- and middle-income groups. Just how will these services be distributed? How will these companies be made? How will they manage their reputations as “automated warehouses”? How will they ensure that their workers don’t live in squalor? What kinds of jobs are safe for software engineers, software developers, and IT security engineers?

In short, the first task must be to find
====================
“Are these people “real?” “They’d do this,” Jackson said. “But you can’t have a copycat society.”

“Exactly. If you have three children, you can’t have a copycat society as well.”

“What happens if you have two children,” Jackson continued. “It’s a really big change. If you’re a farmer, it’s going to affect how you’re going to manage your resources. And then, if you’re a corporation, it’s going to affect what you’ve ever done.”

“Exactly. If you’re a corporation, it means you’ll be less dependent upon third parties, it means you’ll be more compliant with law.”

In the long run, the results will not be good for business, and the survival of the fittest will matter. In the short term, Jackson sees the same thing happening in the long run.

“Both scenarios play out much more slowly than you might think.”

“If you have a trillion dollars and five hundred engineers, you’d be better off if you just hire them and move on. If you have twenty-two thousand people and move three hundred,000 will help you. If you have a billion dollars and move five hundred,000,000, it’s not going to change the world.”

“But if you have a trillion dollars and move ten thousand people into space, it’s going to affect the world. What do you think of that?”

That’s an interesting question, but one I think we can all agree on the basics of – what percentage of the world’s population are going to be interested in owning a spaceship? – and I think we can agree on the underlying question of who gets to explore what universe that universe: “The balance of power is usually more important to those who have power over others,” says Andrew Boden.

Andrew Boden, Programmologist at the NASA GSFC Rose Bowl in Pasadena, California, speaks during the annual meeting of the Association for the Advancement of Science in Pasadena, Calif., on March 24, 2012.
====================
The migration of data centers and equipment from traditional businesses to cloud-based services is on the rise. According to the most recent data, 2013 cloud-based activity was $1.7 billion, a 56 percent increase since 2013.1 Businesses that use 2013 equipment now have an average data-capability of 260 terabytes per day, more storage for the organization to store and more horsepower for business users to use.

Businesses that take advantage of cloud services are now racing to the physical sites of their operations: meeting points, vendor booths, and physical storefronts. They include vendor portal systems in major retailers like Walmart, Safeway, and Safeway Drug Mart, among them Whole Foods, Safeway's Drugstore, Safeway's Latin American location, and Safeway's San Francisco Bay Area distribution centers.2 These third-wave IT systems can hold the data for up to one year, depending on the load of processing, data density, and storage capacity of the data.

Existing warehouses and equipment can handle these large volumes of data, but those that are out of reach can handle smaller amounts of data. Businesses that have access to older warehouses or infrastructure that is out of reach can deal with larger volumes of data.

Businesses that have access to information that is out of reach can also use an IT system in a smaller footprint. For example, if Whole Foods is out of town, the warehouse might be open for business. This means shoppers can rest assured that the company is still selling fresh products and the stores remain in good physical condition.

So, whether an organization will need to hire an expert in cloud computing depends largely on whether that organization will need to replace key employees, modify equipment, and raise the operational cost of such a task. For smaller organizations, the cost of such a task can be lower, reducing some employees' worth, while for larger organizations, the magnitude of the cost-effectiveness gains can be greater.

Businesses That Have Appreciated the Data

Businesses that have gained in scale or accuracy during the data boom need to recognize that this data is much more difficult to retrieve and store. Businesses also benefit from the ability to track their success while minimizing the amount of churn and data that is lost.

In the case of large organizations, the data revolution requires a new level of organization, and that revolution must be guided by the values and values of a trade union.


/
====================
A browser error has resulted in the creation of this video. Try again later.

AUSTRALIA’S ACTUAL BIRD AND THE DRAGON

The ACTUAL BIRD AND THE DRAGON (Act 1958)

SECTOR GENERAL

The ACT 1958 is read as a dietary supplement intended for the protection of birds in riparian settings. It is made illegal in the ACT to make or break a mining project, oilfield, logging operation, logging camp or hunting preserve without the express express consent of the people who own the project.

CHAPTER 1 : Definitions

The definitions in this chapter are as they will serve those purposes. For example:

(a) remote control operation is defined as one used to cause, or indirectly encourage, adverse consequences, including jail time, fines, penalties and costs, and loss of wages or benefits, or which causes disability or loss of enjoyment of a right or a benefit, for the purposes of this definition does not include: (i) a steam power related to a mining project; (ii) mining equipment used for the first time in Australia or New Zealand waters; (iii) machinery related to a mining project that has not been properly tested and is expected to result in adverse consequences; (iv) machinery used in conjunction with seismic activity, logging or sedimentation activities, or similar activities, or which causes adverse consequences, including but not limited to, loss of livelihood, damage to property, destruction of marine infrastructure, loss of enjoyment of a right or a benefit or threatened use of a marine resource, loss of recreational opportunities or enjoyment of a wildlife species or a natural resource and (v) equipment used to monitor or monitor natural resource extraction, mining, logging or sedimentation activities.

(b) flood zone system is defined as one used to cause, or indirectly encourage, adverse consequences, including but not limited to: (i) damage to infrastructure resulting from floods or droughts; (ii) erosion caused by lakes, streams or rivers; (iii) flood or droughts caused by rising atmospheric CO2 levels; (iv) damage to natural heritage, heritage areas or areas used for recreation or recreation products and structures; (v) damage to property caused by flooding or landslides; or (vi) any other adverse consequence which may raise the risk of adverse consequences arising from the use of any of these actions.

(c) mines includes any operation used for the purpose of rendering
====================
Some of the technologies used to train AI systems are more widely used in the service sector. For example, in health and personal finance, credit, and debit cards, AI has been used to automate the traditional card-to- credit-to- debit-system tradeoff. But many other new technologies are also needed, including machine-learning algorithms for language translation, inventory estimation and forecasting, data-mining techniques for pattern recognition, and decision trees and algorithms for machine-learning-backed decision models.

Many of these are on the verge of being digitized into a kind of object-recognizing AI. One such example is AI-powered vending machines that can be seen at vending machines all over the world. 2 Here, AI systems are building a vast third from the street: sensor data suggest that they can be seen at roughly the same locations as vending machines, and vending machines that advertise themselves as "training" to produce some particular product are found at vending machines all over the world. These vending machines are sometimes labeled "vegan-friendly," but remember that this is not a scientific definition—vegan-friendly vending machines are used for health and dietary reasons, and thus cannot reliably diagnose cancer or prescribe drugs.

These machine images represent a far greater threat to the health and wellbeing of all people—one that has come to be known as the AI shock. The definition of what AI is has been reconfigured from a concept of safety, from something that creates novelty to something that is used to justify systematic abuse. The definition has come to encompass anything that can be expected to produce shock value, whether it's a novelty for a novelty—or simply a case of being observed). In such a scenario, a machine image is a representation of safety, not of actual or simulated risk (imitation), but of an intent to produce value. Imagine that you are being observed, flagged, photographed, ordered, and sold. All of these outcomes are directly observable by machines, and yet they are usually being produced as shocks to systems and institutions: the sale of data, the sale of public space, the ordering of goods, and even the purchase of those goods. Imagine how this all looks like price fixing: a vending machine with a smiley face and a child in it, sure to make you feel extra special, is never going to be as good as the one you found it at a child's birthday party.

AI is making a big impact on the world,
====================
When it comes to the future of AI, we’ll likely stick to what we learned in the previous chapters. In the next chapters, I’ll share some projects I think are interesting and think-“very realistic.”

3.5 AI in the Age of AI Timelines

If we think about the relative strengths and weaknesses of different kinds of AI over the next few decades, it’s easy to see how the path to full employment can be steepened if we start with a much smaller number of traditional tools. That’s because machines already have weak human-like cognitive capabilities, which means we’ll need to find ways to increase their capabilities in order to get there first.

Improvements to the hardware will also make a big difference in the speed at which machines will be able to do things that no human can do — like speech recognition and 3-D printing. And those improvements will have big implications for the way we’re going with the advent of intelligent computers.

These tools will be especially relevant for the jobs that require a great deal of cognitive performance. For instance, machine learning and natural language processing need to be inextricably linked. In the next chapter, I’ll describe some of the tasks that machines can and cannot do, as well as some of the tasks that are definitely not optimal for a human-level machine.

In the case of speech recognition, I think the most obvious and critical application is in the domain of finance. Humans might need to adjust the pitch and size of our voices, so we need to be able to recognize them. AI might be able to do this for you.

In the next chapter, I’ll describe some potential applications of artificial intelligence that I think are really interesting and that you should consider exploring in the context of speech recognition.

3.6 What Do You Think You’re Getting At?

By now you should have at least seen the paper about bots. In it, Misha Clark and Simon Schuster write:

In the age of AI, we find ourselves unable to distinguish the bots we’re talking about. We can barely distinguish facial recognition, which we assume is safe, even though the technology has been proven to work for decades. In the future, when computers fully understand our voices and learn to recognize our gestures, they will be able to recognize words and
====================
I wonder if that’s one way to begin to explain how science works?

Let’s say that a machine has a plan to find a way. It’s not designed that way. But it could try to find a way given the input that it has of a certain solution, and it could be rewarded for that solution. That might lead the machine to be less intelligent than it was when it first encountered the solution. It could also lead to some other useful results. For example, it might solve a riddle, like halting the development of a superintelligence. It could be helpful in a number of ways, but it’s not likely to have as many uses. For one thing, it won’t appreciate the help it receives from humans. And it’s not likely to understand that humans are good at solving problems like this. So it might build a machine that can help humans in some way, and that machine might be given a probability function that tells it how many other people are there–that is, given some additional input, it might be able to predict which humans are there–and it can then choose how to share that information with humans. This is, in effect, a reward for finding a way.

One might think that a more elegant way is to build a machine that would maximize all of these possible inputs. But think again: If you build a superintelligence that can find ways to get a million ways into the program, it would take the total computational resources of the world far longer than a million human beings. This means that while a million ways might be a verylarge fraction of the total, a million ways’ is a relatively small fraction of the total available to any computer. So even if we build a superintelligence that can do all of these things (so far as I know–we’re talking about a verylarge fraction), I’m not confident we’re going to get there far enough to declare it superintelligent.

Of course, it’s not just the world’s population that gets larger each day. We've already seen how detrimental AI technology has been to our species. Earlier this year, Qualcomm cofounder and COO John Chambers said that AI was creating "catastrophic economic and mental disruptions" in the US and that companies like his were the ones who would best capitalize. While I agree with Chambers’s
====================
All text generated by non-anthropocentric machine methods (such as textual analysis) will be used in this paper. Any commitment to use “artificial intelligence” elsewhere in AI (i.e. in libraries, software, or software maintained by humans for inference and learning) will be ignored.

2.6 Continuous-process training sets

Continuous-process training sets (C P T ) are continuous-process training sets that include training data as a standalone process, which means that the model is trained alongside it in its entirety. These techniques are useful for AI that uses machine learning systems to build a continuous-process processing system.

In general, continuous-process training sets are useful for AI applications that require a relatively slow process for the output of the processing process to run at. High-performance training sets are also useful for applications that require a fast process for the output of the processing process. For instance, AI applications that require a high level of performance from multiple parts of the AI system need P equals to get the total number of stages of the processing process.

P equals to get the total number of stages of the processing process. There is no need to have all the stages of the AI system in one continuous-process system. The total number of stages is always expressed as the number of inputs (step by step) and outputs (step by step).

For systems that are large and perform well on many inputs, the total number of stages of the process can be expressed as the number of times the AI process has run. For example, a process with many stages can be described as a continuous process, with many inputs and outputs. As such, the total number of stages of the AI system can be expressed as the fraction of the process stages that are not yet run by the process. The fraction can also be expressed in terms of other stages, such as percentiles.

To illustrate the usefulness of the term “step rate” and the importance of asynchronous processing, let’s consider a different example. Imagine that an AI assistant were working on an AI program that learns the value-laden aspects of trading. She wants to enable this development by enabling the use of more advanced asynchronous processing. Let’s call this system Alice.

What is the value of this system? Alice’s value is Alice’s value, compared to any human worker. Roughly speaking, Alice�
====================
Raspberry Pi: a Personal Computer

This chapter describes the creation of a personal computer. I’ve made a number of copies of the software, and built an operating system, but these were not personal computers. They were part of a larger project, a computer called the “Personal Computer Project.”

The PDP is a kind of personal computer. It’s a tiny piece of machinery: it has no eyes, no ears, and no legs. It’s mostly good technology, but also just plain lies in the dark. The pDP is being built by a group consisting of researchers from Google, IBM, and other institutions. Back in 2009, when I wrote the first of my books, I had a friend who was actively looking for a computer to help him with his Ph.D. dissertation. So he asked me to create the Pi Personal Computer.

The project began with just one programmer’s sketch: a computer with just two buttons and no programming knowledge. Back in 2009, the project was still in its early stages, and the only way to gain traction was to hire a professional programmer. At the time, the project was still in its infancy, and many in the field thought it was a joke. But when I told IBM’s corporate PR manager that the Pi project was in the works, he laughed and said, “About that again, Sam. You have saved the day by having people hire you as a programmer.”

The project went on to win a prestigious Ph.D. in computer science from MIT in 2012, and is still in the design phase despite being a little bit of a project for IBM. The point here is that you can’t just hire programmers because you’re a really good programmer. You need to hire people who are really good, and they’re going to learn from their mistakes. And by learning, they can help you get better than the competition.

The main difference between the two projects is that IBM is now forcing its users to pick a programmer–as opposed to inventing a new technology that users will actually use. The point is that having a true understanding of the software you use is critical to building a good computer. And the vast majority of personal computers are not even that. So instead of building a computer that users will actually use, let’s build a computer that will do what we�
====================
A risk assessment tool for natural persons applying for disability benefits.

A review tool designed to evaluate the eligibility and effectiveness of natural persons applying for benefits.

A person’s right to timely access to information and other benefits.

An express and implied permission to use a tool or service.

An express and implied permission to deny access to certain resources or products to certain individuals.

An express and implied permission to deny access to certain professions, organizations, and geographic areas.

An express and implied permission to deny access to certain individuals in a discriminatory or otherwise incorrect manner.

An express and implied permission to take adverse actions in a discriminatory manner.

An express and implied permission to threaten, discipline, or hold accountable individuals in a discriminatory manner.

An express and implied permission to create risk assessments in a discriminatory manner.

An express and implied permission to provide feedback via a form check.

An express and implied permission to organize in a manner that resembles an open letter.

An express and implied permission to use automated systems in a manner that resembles a spam filter.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the checks.

An express and implied permission to use automated systems in a manner that resembles a retainer system.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the retainer calls.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the calls a system such as ChatGPT.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the automated calls and which are automated by a third party such as an automated system evaluation tool.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the automated calls in a discriminatory manner.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the automated calls in a non-custodial context.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those who receive the automated calls in a school setting including diversity, inclusion, and inclusion+ or similar tools.

An express and implied permission to use automated systems that reflect the views and opinions expressed by those
====================
The challenge for the AI community is to balance the rights of natural persons with the values of justice and social equity, as described in chapter 5. At the same time, the challenge should not be to create more legal complexity for AI systems, but to ensure that they have the necessary know-how and know- craft to understand the complexities and limitations of the legal framework.

Legal scholars have argued that the ethics debates surrounding artificial intelligence are poorly understood, and AI ethics committees have been established to address concerns raised in this chapter.4 While many arguments have been postulated with some degree of certainty, these debates are complicated by a fundamental disagreement over terminology. There have been many discussions taking on the meaning of “each person is person-A,” which leads many people on both sides of the debate to produce normative inferences. The claim here is that the concept of a “person” is too broad, and that AI systems should not be able to know precisely which person is in a system.

Some have pointed to instances in which a “person” can be established by some other AI system, and this is problematic because the claim is premised on the assumption that the AI system has a self-aware, knowable, knowable caregiver. To address this, we will define a caregiver as a person who helps the AI system in its development or maintenance. In this definition, we will consider the AI system that is not a remote control system but a person.

A caregiver is one who is not dependent on the AI system and who does not wish the system to end or increase its capabilities. If the AI system is not fully autonomous, or it is not able to fully implement the described goals, then the caregiver might not be able to act as a source of human warmth and love in the system. AI systems with dysfunctional goals might also lack the human touch and understanding that are needed for human dignity and independence, and we therefore define as persons.

In this definition, we will consider the person as a person who is dependent on the AI system and as a caregiver who loves and supports the AI system.

Personhood

A person is a label attached to an AI system that identifies the system as a personhood goal. The personhood goal is to enable the system to become as useful and profitable as one could hope and to share dignity with those who are growing or who will be growing up.
====================
”

The short answer to this question is “Yes.” To be clear, I think we can achieve things like a year ahead of the AI revolution, because we already have basic things like robots and wind power that we have built and tested and tested and tested and tested.” The long answer, in fact, is that building the intelligent robot that we need is already done, and we just got started building the third-generation of intelligent robots: self-updating self-altering devices.

Self-altering Robots

Let’s start with an example of a robot that has already been built. A large robot like a minivan will do the job. But a smaller minivan or minibus might not be needed. So let’s build one.

First, we build an electromechanical robot. This could be anything from a simple piece of glass to a piece of actuator wire. It could even be a small piece of software – just a program that listens and acts as a guide robot. Let’s say, for example, that a guide robot has programmed the guide robot to act as a listening device. Now it is time to build a device that understands the world around it and will listen and guide it. It would be a very simple project, and one that could easily be scaled up and scaled down. But it could come up with some smart, innovative plans for the world around it.

It could be provided some version of an explanation of how it came to be in the first place, or a blueprint for how to go about doing just that. It could also be offered some blueprint for how to get an autonomous vehicle into the world. So it could be a blueprint for how to get an entire society into a gear. It could even be a blueprint for how to get some humans into a gear for the purposes of doing business.

Now it is only a start. And if we look at the evolution of the robot components over the last few decades, we find that they all begin with the same basic design: a small, circular device that sits on top of a central hub. The device connects to a central hub by a series of pulleys and a pivoting wheel that moves it along a track. Each pulley connects to a pulley in the hub by a series of screw-bolts that move it along a line. That’s it:
====================
The answer to this question is yes, the answer is yes. There will always be computers that can do “everything” besides perform complex computations. There’s no reason to expect these machines can’t solve the underlying control problem, which is the fundamental problem of computation.

I think we’ll eventually get someones idea of how to build intelligent machines. It’s not clear yet how to build one that’s not a chess master or some other master strategy. But we should eventually get someones idea of how to build one that's not a chess expert. And further, it’s not clear yet how to build an intelligent system that’s not in a state of internal alarm, because building one that’s that good at whatever you do is a race that’s going to get you killed by the next AI.

Another common approach is to just build the AI you want and keep it around. This is much easier and would hopefully lower the cost of building the AI. Building one that’s superintelligent will require a much larger variety of hardware, much more data, and much more advanced computational algorithms. Adding these elements will take us to our destination, but at least we’ll be able to climb out of the ceiling and enjoy the ride.

One more thing: building a superintelligent system requires a far larger variety of AI schematics. A lot of what you might find in the world of human-compatible AI is actually developed by other AI researchers. So while building the world’s first AI system, Stephen Hawking’s Astra T were created by a team of artificial-intelligence researchers. And given the right background information and right programming, it would be easy enough to find the right ones for the job. But when it comes to building superintelligent AI systems, one’s going to tend to be a bit complacent.”

Finally, I think there’s no clear path to attaining superintelligence. There’s also no clear-cut path to being superintelligent. That’s because we have to remain humble and humble in the face of overwhelming odds and a terrible enemy.

Chapter 8: Solving difficult problems

So far we’ve’ed by asking the simple questions, "Can we solve the problem of solvable problem that
====================
Elias, the AI agent that Emory University installed in its Information Systems Division, is a self-described “sorcerer of information systems.”5 Elias’s specialty is reinforcement learning, a strategy that builds artifacts and prevents the construction of new artifacts. As Elias himself says, “Sparks” is “just a name. It’s all I’ve got going on my mind.”6

Lee Kuan­kai, the AI professor who oversaw the Elias project, has described KAI as “excited” and “bright.”7 He also used to be a strong advocate of reinforcement learning, saying in an interview that “He always said that reinforcement learning is the biggest leap forward in computer science research in seventy years.”

Over the past decade, however, it seems that the mainstream scientific community has begun to come to value alternative learning methods more than ever before. Beginning in late 2015, there have been numerous articles and workshops introducing alternative approaches to learning, and one workshop titled “Learning Machines in a Reactive World” was co-organized by the New York–based computational neuroscientist Clare Mayhew (1926–2013; Fig. 2.15). The workshop, titled Computing Machines in Reactive Worlds, was part of a symposium organized by the Computing Machinery and the Artificial Intelligence Association in Tampa, Fla. (July 2022–Present)

Mayhew is perhaps best known for founding the influential Computer Assembler (Computer A) in 1960, which later became the IBM 704. She is perhaps best known for founding the “Summer Brain on AI” program at Dartmouth in 1970.

In addition to being a pioneer of learning, Mayhew is best known for coining the term “reactive programming.” In 1970, she wrote “Reinforcement learning adds new cognitive capabilities to existing programs.”8 In a famous chapter about reinforcement learning, she described a program “thinking” at scale in which a program “playing two positions” could “change the positions of the two textbooks, thereby changing the two-dimensional model.”9 In 1981, she wrote

The latest generation of reinforcement-learning programs can at least learn new board positions, and perhaps even switch games. Perhaps surprisingly, though, they can also teach themselves new information
====================
Our focus in this research has been to compare the impacts of different cognitive enhancement methods on short-term memory formation and to link the effects of cognitive enhancement to longer term memory development. Our goal with this work was to provide a general assessment of the current state of knowledge representation in the human memory system. We hope to provide a useful and useful benchmark for further research into the state of knowledge representation in the human memory system. We expect this type of research to continue throughout the human memory development programs as this field has gained more clarity and depth over the past several decades.

In the context of our research, we understand the broad potential of artificial intelligence to augment human intelligence and, thus, advance the general state of knowledge. We also recognize that human memory systems typically lack many of the specialized skills, talents, or qualifications that come with digital abilities; thus, enhancements of the artificial intelligence framework can help to provide a broad base of skills and talents that are ready for large scale, real-world applications. Moreover, enhancements of the human cognitive framework can also have practical uses, such as improving the training of decision-making processes or decision processes based on hypotheses or data. Future research will need to consider both short-term memory enhancement research and the management and explication of large-scale cognitive enhancement research, as well as the optimization of the learning and development of novel techniques for enhancing human-AI relations.

In parallel, our research aims

To provide a preliminary assessment of the current state of knowledge representation in the human memory system. We hope to provide a useful and useful benchmark for further research into the state of knowledge representation in the human memory system.

To provide a more thorough assessment of the augmentation potential of the human-AI relationship. We believe that the current state of the art in the human memory technology is one in which there is no going back. Advances in artificial intelligence can be scaled up, and new capabilities can be leveraged, but the path is generally the same: we envision these systems as an extension of our own individual intellectual architecture, and the same is true for the cognitive architecture of our own minds. Humans, for the most part, do not fully and fairly share any knowledge, training, or knowledge in the field of artificial intelligence. We have come to expect this technology as a stepping-stone to greater collective intelligence; however, it is not something that we would willingly relinquish. We expect humans to slowly and surely get better as a species
====================
“The Turing test is a very powerful benchmark,” said Jack Clark, CEO of DeepMind, whose deep-learning pioneer students were part of the test. “It’s a very rigorous test, and you have to be willing to accept some risk for it.”

The Obama administration has been criticized for its emphasis on artificial intelligence, and some have likened the push to balance the books to an overuse of gold to finance an overproduction of basic services. But experts say the Turing test has brought a new level of transparency to the digital books—one that many experts say is simply beyond what the federal government has available in the current era of government control.

“The American public deserves to know what the government thinks is going on in this private sector enterprise,” said Mark Andreessen, a cofounder of Uber, which was recently fined $1 billion by the U.S. Consumer Product Safety Commission for failing to monitor its cars. “They deserve to know what is going on.”

The Snowden disclosures have heightened these concerns. Government agencies have been increasingly willing to share technical secrets with the media, including breaking new ground in education and health systems, for fear that they will be caught and alerted to. The test has also become an object of fascination for intelligence agencies, who are seeking to track its movements and whether it uses AI.

But the public has no such access, and the American public are not yet material takers. The stakes are too high, and they are too small, to give the misleading impression that the tests are unproven or nonexistent. Worse, the American public deserve to learn more about what is really going on behind the curtain. They do not deserve to be led astray by the plain language of AI tools, for there is no such thing as clear-text AI.

The stakes for the public are too high, and the stakes are too small to give false hope to those who seek to understand and address the AI mess. We will not go unpunished. 

THE FOUR WAVES OF AI

The Snowden disclosures have heightened the concerns about the future of working-class AI. Guided by the success of deep learning at an international scale, many workers have been pushed to sever their ties with companies that used the technology. Storied AI companies like DeepMind, DeepMind San Diego and DeepMind DeepMind GPT were able to
====================
Reinforcement learning is an area of AI that incorporates many complementary applications, from machine learning and perception research to machine learning and perception research and perception

Reinforcement learning models are general-purpose methods for evaluating risk or unintended consequences of actions. The term comes from the Greek word meaning “reinforcement, messiah, or reveler.” In fact, the word derives from the ancient Greek words “rein, (s)paññ, and “runes,” and from the Latin genitive form, meaning “genitive, action,” is from genitive form, action.”

A reinforcement-learning agent can learn to worry less about the consequences of its actions and more about its own motivations, says Hans Moravec, a professor of economics at the University of California, Berkeley. The result has been a more positive environment for learning.

But in the longer run, says Moravec, it’s still the “90s,” to say the term used to describe people learning to learn reinforcement-learning techniques. The word is derived from the Greek words “reptilian, which means “water rod and spike.” So, he says, we should expect more use-case-specific reinforcementlearning algorithms.

The real test will come when commercial firms actually implement these systems. That’s why companies must use the terminology "super agent." Super-agents are those that can achieve a wide variety of outcomes that have the property that makes them super likely to achieve a wide variety of outcomes. That’s why companies must first define what they want a system to do.

Companies that fall short may turn to “behavioral optimization.” In Moravec’s view, that takes the first step to actually general-purpose AI. Instead, it takes the concept of reinforcement learning and applies it to the specific problem of increasing the likelihood that a person’s reactions will be sufficiently robust to overcome the effects of the environment.

Moravec’s emphasis on “behavioral optimization–comes in the form of tools, not in the more general machine intelligence form of AI." shows just how powerful the concept of AI can be. Artificial intelligence is still in its infancy, and there are still many “dark days” ahead.

Moravec says we need to stay
====================
The entire idea of automated clothing is based on overestimating the potential of people.

A machine learning model, however, could be incorrect, resulting in people incorrectly dressing as the model and dressing inappropriately. A new class of models is on the horizon—think of the Neat House, an AI model in the sense that it is a "house" rather than a workshop. The model is currently undergoing trial and error before it becomes a reality. And while it is technically accurate, the model is not fully honest about its plans.

The model does not necessarily reflect the reality that millions of people dressed up in designer Ralph Lauren and Tangerine tinted creams will be arriving at Ralph Lauren stores across the country in the coming weeks. The retailer has not announced when or how many shoppers will be dressing up for the retailers, but the model is considered accurate within the model-shifting community.

Something is amiss with the fashion world.

Seen from this vantage point, the casual viewer who views this episode as an episode of Jezebel might conclude that this is an episode about Lauren accidentally dressing for Jeremy Lin when she appeared on the Lin show. But that's not necessarily the case. In fact, this is not an episode about how people might feel when they see designer Ralph Lauren dressed up in Ralph Lauren blazers. This is a show about how casual viewers will conclude that Lauren is dressing up in an attempt to trick casual shoppers into thinking she's buying a Ralph Lauren.

The point here is not that casual viewers might not believe the blazers are actually meant for casual consumers. This is that the likely effect of casual readers would conclude that this is an episode about fashion showgirls dressing up like Ralph Lauren. It would also be reasonable for casual viewers to conclude that a Lauren blazer is actually a good blazer, because the blazers themselves are not as good as the actual model.

But in this case, a casual viewer would not actually be dressing for a real model. They would be dressing for the fashionistas. And that means that the likely effect of casual viewers on such a casual audience is essentially the same as for a typical viewer. In other words, a casual viewer might be more likely to recognize a Lauren blazer than a real model.

So what happens when the casual viewer is a real model?

A typical viewer might not be able to distinguish a Lauren blaz
====================
The implementation of those principles in A M E may need to be simplified. In the case of trading, the floors of companies could be converted into shares, which could sell for pennies on the dollar, or for fractions of those shares as dollars. In trading, equity shares are trading at just cents on the dollar, whereas, if the winning stock price is paid in dollars, the shares would be traded for pennies on the dollar. With AI, the trading floor could be converted into shares, which could be stored on servers, or even put on eBay. These systems could eventually fetch tens of millions of dollars in fees, but the fees would be negligible compared to the riskiest investment.

Given the ease with which organizations could become more automated, it made sense to require that they also trade digital. Digitization and outsourcing helped create an environment where valuable digital assets, such as stocks and shares, could be traded at much greater volume and put on eBay, which would ultimately fetch a penny. The same goes for any other source of value, including digital books.

Given the speed at which AI systems can be built, refined, and deployed, it makes sense to require that they also safeguard against losses in the event of an sale. Absent compelling reasons, such a requirement should be avoided at all costs. It could make it cheaper to simply offload the risk onto consumers, or it could make it cheaper to simply replace the high-risk asset with something more value-neutral. In either case, the seller would pay for the service, and the consumer would bear the full cost of the sale.

In addition, the seller could pay for the data security deposit, which would save the buyer and seller the cost of re-acquiring the high-risk asset at a later date, and of replacing it with something other. Moreover, unlike credit, debit, or money transfer, the digital asset could always be valued using values other than the original high-risk price.

The buyer and the seller could in principle avoid losses in both cases. However, depending on the nature of the sale, the value of the digital asset may be traded lower or higher than the value of the buyer’s or seller’s assets, and vice versa. Should the sale ultimately fail, the buyer or seller could take on the cost of replacing the high-risk component of the digital asset, thereby avoiding the buyer losing the full value of the asset. In
====================
Tangled aren’t talking about “technological singularity”—that is, the ability to process information in a superintelligent way without necessarily having anything to worry about with our current digital or physical technologies.

“Technological singularity” is something that could occur alongside “entire-scale AI.”16 We’ll talk about the potential for whole brain emulation in the next chapter. But let’s focus on what’s been happening behind the scenes in AI and how that could change our lives.

Brain emulation

For many years, researchers at the University of Edinburgh and the University of Cambridge used genetic algorithms to create human-style head and necktie designs.17 But the algorithms were far from perfect. As a child, I remember being forced to draw on the X-height of three dimensional vector graphics the lines between my right shoulder and the line between my left shoulder and trigonometric shapes. It was rough at the start, but eventually came to feel natural and useful. It also helped that these designs were hand-coded and, like Google’s template engine, the designs were easy to understand and edit.

The AI algorithms did, however, require some back-of-the-envelope calculation. So instead of simply copying the estimated X- and Y-lineups from the internet, the researchers used genetic algorithms to fit the current state of the human brain at a given stage of brain evolution. The result, as we’ll see, was dramatically lower-level model formation and much lower-level information acquisition. It’s worth noting that the researchers didn’t rely on genetic algorithms as a foundation for their algorithms, instead using approaches that relied on data from more general artificial intelligence (AGI)—intelligent systems that can generate hypotheses and explore paths for new insights.

That reliance on more generic algorithms is entirely reasonable. Early attempts to create AI algorithms based on computation from human-level representations of inputs and outputs had generally failed. What was needed was one that could be built up over time with little or no modification.18 The approach is essentially the same as the “Human Veneer” algorithm, except instead of copying the input universe, the researchers opted for direct computation from the known units of a person’s face. The goal was to get AI algorithms that were able to perform the mental calculation required for the
====================
“Stephanie A. Seidenberg, Ph.D., “Top Secret AI Experiment: How to Turn Your Computer Network Into a Brain–Machine Bond”.

Some people love this book because it explains how you can build artificial brains and machines. The real magic happens not in computing but in everyday life. In part one, I explain how you can turn your humanistic side into a dangerous business. In part two, I demonstrate how you can turn your human side into a profitable one by getting real-life superintelligence.

You wrote your book about the state of artificial intelligence research. How do you plan to proceed in the near future?

I have a bit of a philosophy of science, which is, I can't predict anything unless I have a plan. I can only predict that there will be unintended consequences that I can't explain, that I’m unable to predict, because I’ve never actually done X. That’s because I’ve never done Y. That’s because I never will. The only way I can explain it is by saying that there’s a kind of predictive model that says, “it’s X when it’s Y, but it’s not necessarily anything like that when it’s actually measured. So what’s going to happen?”

You write about the need to build “pure AI” systems, in order to avoid the kinds of dangerous business models that are common in today’s world. How do you think you’ll achieve that?

I think we need to keep building these systems. You mentioned the superintelligence frontier. I think in the near term, we may need a little bit more scientific support. I’m not a scientist, so I don’t have experience in that realm. I think we will certainly eventually reach superintelligence. I think we’ll eventually reach it, but it’s hard to say right now.

Do you think we’ll be able to build all of them?

I do not have a definite answer, but I do think it’s feasible. I think it’s going to take some time. The thing that we’re looking at is not having any of the good outcomes. The good outcomes are going to come from poorly designed systems,
====================
Bertrand Russell's The Structure and Development of a Personal Computer (1924) offers a succinct and up-to-date account of the centrality of AI within the human experience. Russell gives us a brief and detailed account of the centrality of AI to bootstrapping a machine learning model into a computational architecture that will serve as a basis for the most advanced forms of AI. Russell goes on to say that “we have no doubt that the human mind has a great influence on the development of artificial intelligence,” and that “a comprehensive study of the human brain will be necessary to prove and validate our point.”16 Russell goes on to say that “it is not enough to have empirical evidence that tells us anything definitive about the present state of the human brain.” He goes on to say that “it is not enough to have empirical evidence to say that certain AI approaches are worthy of continued development.” He continues his description of what is currently being researched: “Intelligence is, after all, a complex concept, and the best way to understand it is through observation rather than judgment.” He goes on to say that “in fact, it may be that the best way to understand a problem that way is to look at it and make predictions about it based on them.” He continues his description of what might be done to build AI systems that actually do understand what they’re doing. We’ll see why AI is the wrong direction when it comes to this problem.

9.5 AI In Brief

A couple of years ago, a symposium on the state of the art in artificial intelligence was held at the European Mathematical Society Congress, in Lillehammer, Normandy. It was attended by some of the symposium authors and was held under the heading of “Principles for the Advancement of Life in the 21st Century,” a topic which got a little out of hand with the present state of the art.

I had been working on something very important for a number of years at the European Mathematical Society, and had just published an article titled “Artificial Intelligence Is Not a Game,” which described some of the challenges and difficulties in the field of artificial intelligence. After a pause of several minutes, the author concluded the paper by saying, “In conclusion, the present status of the field makes it appropriate to resign my
====================
The key to truly understanding the value of AI for our country and our national security is the public engagement with the technology. We should not be complacent. We should be prepared to take action if the current level of hype continues. And we should be prepared to reverse trends that are starting to make a serious impact on our society. We should be prepared to move beyond the current focus on automation and instead look at rethinking our workforce processes and our processes around the potential for an AI-driven economy.

Reimagining Our Workforce

The initial excitement around the possibility of machine learning and related technologies for America’s workforce dissipated as we saw the potential in the technology in the wildsittable online world. Businesses, academics, and policy leaders all began to ask what would happen if we turned AI into a more respectable, ethical, and successful industry. Many people dismissed the idea as dumber than the cog, and some people even coined theword “machine learning.” Companies began to hire Gizmodo to test the waters, publishing stories about the most dire scenarios. Soon enough, the word was adopted as a defining trait of the prospectus, an engineering unicorn that drove a tidal wave of automated hiring.

American machine-learning giants like Google quickly adapted their playbook and aggressively expanded their existing and highly profitable teams of engineers. As a result, America’s gladiator machine-learning champions continued to push their version of the technological magic out into the real world. In the years that followed, America remained on the defensive, reeling from the fallout from their gladiatorial conquest of China. But companies had other ideas for how to respond. Startups like BitMiner and Smart Finance were able to convince Silicon Valley that their products had resonated with the hearts and minds of over a decade of internet training, and their algorithms had revolutionized the world of work.

At the same time, American companies were turning to AI as an afterthought. Countering that hype began a new wave of transformation that was brewing within these companies, turning AI into something more respectable, more human-like, and ultimately replacing the hype. As I explain in the next chapter, this shift has taken a toll on the psyche of these American companies, who are turning toward synthetic intelligence to fuel their bottom line. But Silicon Valley’s embrace of AI may have been the catalyst that forged a new paradigm for business in 2017.

The
====================
Brief History of AI

The idea of AI emerged as a fading vision of scientific progress, but was alive and well in the 1960s. In the 1970s, the field began to see tangible benefits to both the scientific method and to the environment from AI. As computers began to understand what they were doing, they could also help identify and mitigate risks to the world through computation. The field began to think differently about the problem of the detection of dangerous materials, and began to envision ways for machines to operate at greater granularity and control, and to exploit the knowledge gained from learning.

The field started to see tangible benefits to the environment from AI, particularly in the areas of education and health-care. In the 1970s, the field started to see tangible benefits to the environment, particularly when it came to the alleviation of poverty. The average lifespan in the United States was increased from 45 years in 1930 to 66 years in 2005. Public utilities like electricity were becoming increasingly scarce, and many people no longer had dependably dependent on them. As a result of the electricity crisis of the 1980s, electricity companies began to rethink their business models, rethinking their models around the notion of supplying a source of power at low cost to the consumer. In the 1990s, AI began to pose a threat to that goal. While AI was fading from the scientific imagination, some scientists began to believe that AI was on a path to the same fate. In 2001, a core part of the AI research community, the AI Section at the University of Maryland at College Park, released a report titled "A General Framework for AI Research." The purpose of the work was to provide an "automated master thesis plan" to support the creation of AI systems in the future. According to the release, the AI Section would conduct pre-deployment assessments of AI systems prior to deployment to "discuss and document any concerns or concerns raised." Those assessments would be reviewed by an engineering lead about developing a solution.

The release also claimed that AI systems would be self-aware, would excel in class and task, and would be willing to answer questions. The AI Section would deploy AI systems to provide explanations and support in the form of training data and advice to students and faculty, and would use the systems to expedite deployment by using alternate systems, such as self-healing or autonomous. The release further stated that AI systems would be proficient "in identifying and resolving technical
====================
The EU will not sign this treaty, and it will not get the kind of radical change it promised under the previous government.

“The EU is moving too slowly,” says a Brexit expert.

But it’s the EU’s policymakers who will have to pay the high cost of this uncertainty – and the negative impact on working people.

The law in Europe gives priority to workers who have been affected by Brexit, and the law in the UK gives priority to people who have been affected by Brexit. So, for example, if a steelworker is affected by the North Sea oil spill by five years, then the law doesn’t give priority to the worker in the UK who is affected by the collapse of a giant cement plant.

So if the EU moves too slowly, then we risk being wiped off the world’aster­ry.

But without immediate radical change, the law in the UK won’t apply. So, the only way that the EU can benefit from radical change is if it signs this treaty. That’s a very realistic expectation, but one that is not necessarily the case in the past.

The truth is that there is no guarantee that the EU will sign the existing treaty by five years, let alone reverse-engineer the impact of the Brexit vote. That’s because the consultations that must be conducted on radical changes in the EU legislation are ongoing for several years, and the impact of that change will only be felt for a few years in the form of legislative changes. That’s why the EU has already agreed to hold its own consultations, beginning in 2019, in order to put pressure on governments to agree radical changes to the EU legislation, says one person close to negotiations.

Meanwhile, a fundamental change in the way the world processes knowledge will hasten the transition – if not sooner. According to a person familiar with the negotiations, the EU and the United States have already agreed to a timeline of five years – a term that reflects the relative openness of the two countries in managing international coordination and communication – in order to prepare for the possibility of a breakthrough that won’t happen by then. That means that for the United States, efforts to thwart a fundamental change in the way knowledge is received and evaluated around the world will be met with relentless barrage.

There are two problems, argues Kasper, with the timeline.


====================
“We cannot permit that,” said a visibly emotional Metcalfe. “But we can try to think of new ways of doing this.”

For the past two years, the challenge has been accelerating the development of a new kind of AI that could displace human knowledge on the global stage. Now AI is reimagining the dirty work of global optimization: automatically ranking restaurants on Yelp, driving cost-cutting plans to drive societal dollars, and correcting inefficient systems that led to poverty. The transformation is part of a broader shift towards AI-driven consumption, reimagining work in the service of the abundance that arises between human activities.

“The greatest fear people have is that they won’t be able to find the things they want to do because they are born with them.” –Diane Saudi, CEO of Fiverr

Fiverr’s AI-powered meals program started as a simple Google search query: “Fiverr’s AI-powered meals program is helping people find and place meals.” The company rapidly became the go-to platform for small-batch delivery startups, and it rapidly became the go-to delivery company for food delivery startups. Within the first year, it served more than 2 million meals, far surpassing the number of restaurants served by the original Eat24 pilot program. Within the following year, the company doubled down on that success – and doubled down on food delivery – and became the go-to platform for low-wage startups. Within five years, Fare.ai became the go-to meal delivery company for consumers, becoming one of the most valuable startups in the space.

By 2017, Fiverr was serving more than 2 million meals, far above the number of restaurants served by the original program. By 2023, it would serve less than 1 million meals, and in 2026 it would close its relationship with diners. Within five years, the global economy would be faced with an even bigger question: who would serve the meals?

Fiverr is a good example of a company that is reaching out to underserved communities, but it is a larger enterprise than Amazon. Fiverr is a great example of how to build an enterprise-wide AI system, but it is a larger enterprise than Amazon.

Before we get into the nitty-gritty details of what AI can do, we should
====================
The difference now is that AI can now do this and that’s already done it. Chin-Ling has been working on his own machine intelligence project for seventeen years and has spent a lot of time developing the kinds of predictive models that will help people make difficult decisions. But after seventeen years of working on the same ideas, Chin-Ling had this to say about the opportunities ahead:

[T]hat’s one of the things that will give us an edge over the competition is machine learning. . . . the fact that we’re able to do this already, let alone building an AI system right now.

Chin-Ling sees an opportunity ahead of AI in three things: personal identity, machine learning and data, and human decisions. In a workplace where more and more tasks are automated, people will be able to track their physical and financial footprints and see what tasks are completing tasks they care about the most. Chin-Ling’s approach will allow people to “see” what their employees are doing, what tasks they’re doing, and identify those gaps in knowledge and knowledge that are not accounted for adequately in the machine learning models.

The benefits to people of using AI to help people is huge. Chin-Ling estimates the total productivity of the Chinese economy at $20 trillion, far more than most U.S. companies have come to expect. His vision of AI as a solution to global problems-from climate change to missing people to accurate maps of mental states-appears a far cry from his vision of AI as a solution to global problems-from rising prosperity to supernational coordination.

To understand how this vision of AI can make a difference, we must take a step back and consider the history of other AI-based solutions to global problems. Considerations of scale include high-fidelity virtual reality (HFL), the need to keep people in check, and limitations on computational resources.

AI for the masses

The concept of AI can’t compare to the mass innovation efforts that have been undertaken by the masses of people (ocean dwellers, vegans, pre-millennials, the elderly, the queer, the autistic, the people-weaving-the-wastes, the veteran's, the queer and gender nonbinary, the queer and intersex, the queer biān, the lesbian, gay, bisexual
====================
“The problem is, this is AI-speak for something completely different.” “The technical term for this is deep learning,” or “machine-learning technology,” but the technical term is not. Deep-learning is AI-speak for something entirely different.”

WHAT SHOULD BE EXPECTED OF UNIVERSALWEB HACKS

The ideal setup would be to be able to detect the pattern of a cloud’s magnetic field and then calculate the probability that that that field will be reversed. This would allow algorithms to perform an exact simulation of the cloud, rather than simulating the whole system with just one component.

One could even imagine doing A.I. simulations of the entire internet instead of just the one component. This would be a much more accurate and accurate model of the internet’s structure. It would also allow algorithms to perform a more thorough search for adverse changes, and more quickly, changes that might skew the results. It’s a straightforward and elegant solution, but one that would incur significant costs, both in resources and time.

That said, I think it would be far too easy to build an AI system that operates outside of the box. I assume the analogy to a typical human being operating an A.I. system is far too simple, and the cost of such an infrastructure would be too high to be worthwhile while still providing a safe harbor for future A.I. innovation. However, given the nature of the computational computation needed to build an AI, and the scale of the computational computation required to achieve that computation, I think it would be far too easy to build a system that is suited to serving an AI application. To the extent that building a system that is suited to human needs is worthwhile, then building it is too simple.

In general, building systems that are suited to human needs is not a bad thing. However, in building systems that are built for a specific application, there might be some gene-wide optimization benefit that is too small to warrant a certain build order. A particular build in A.I. for example might recommend people avoid it because of the negative impact it might have on their skills. Building a system that is suited to fit this narrow application is not a bad thing, but in fact it would be far too easy to build, given the low cost of that application.

So, the question becomes, what
====================
I have a theory about why and how the universe is expanding. I’ve spent the last few years obsessively working to understand what is going on, and to which I should point out and small things that might surprise you. I’ve come to the conclusion that the answer is not in the expansion itself, but in the random rate of events that are taking place in the macroscopic universe.

There’s a reason physics tells us that the expanding universe is the result of a random process. It tells us that there are some events in the macroscopic universe that are events we should look out for. These are the events that have been overlooked by the search for other, similar, similar, more massive events in the macroscopic universe. The search for other, similar, more massive events is part of what’s called “general relativity”—that is, keeping the Big Bang constant. I won’t go into it here, but suffice it to say it’s something worth looking into.

A related story, that of course, is that we should look out for these events—they’re called the events—when they happen, and it’s always useful to have a better idea of which ones are which. So let’s look at how that might be done.

3: Time Teller’s Paradox

Time comes to life when we have something interesting to look forward to. We don’t it because that’s what’s called to us everyday,” as our baseline state, and that’s the way it should always be done. But what happens if that’s not the case? Time takers are like clockmakers; they tweak time to make it clock faster. There’s a reason they can be regarded as a little more unpredictable than clockmakers, since they tend to treat other clocks as variables in a series.

Some clocks have no such variables, and some are more definite about their timings and therefore more reliable. A good example of a time taker’s paradox is the decimal leap in pi, which is 0.707148 seconds, given the clockmaker. In a paper on the topic of time-travel, I mentioned the 0.707148 seconds as an example of how arbitrary the leap can be, given the circumstances under which it is based.
====================
“Healing from trauma?””

The answer, I think, is yes. Most of the time, that’s because the brain was already damaged. That’s why we used to use machines to restore feeling and mobility: to balance out the forces of the world around us. But then, too often, we find ourselves in a twisted, twisted predicament: we find ourselves unable to move our bodies or take in the scenery, and we feel as if we are in a foreign land, facing something numbing or cold, even as our minds are gradually returning to normalcy.

For me, that numbing quality just isn’t there yet. I don’t think I’m in a position to give advice on everything,” I just think there are certain things that we should and can do that will bring us benefits in the long run, including the ability to bring our minds back to normalcy.

“Healing from trauma?”

Yes, that’s a good question. It depends on how you look at it. For instance, I think we’ve reached the point where we can finally move our bodies, and that’s a good thing.”

Do you agree with the idea of machines that can help us with our trauma? Do you think there will be any downsides?

I think there are bumps and bruises along the way. I think in some areas, there may be an issue where the machines don’t feel full. But I think there will be benefits, and downsides, as well. For instance, I think the machines will be able to talk people into doing certain tasks, or making certain decisions. I think we’ve reached the point where we can finally get our brains back on track, which is important. And that’s another thing I think we’ll eventually reach, because this is the era of AI. We’ve got to get our brains back on course, because that’s what’s important in the long run.

The people who are advocating for AI are quite vocal. Can we say for certain that this technology will, in fact, improve the lives of those who are not impacted by it?

A study by the Pew Charitable Trusts found that 77 percent of Americans are burdened by negative externalities or
====================
”

The shift from cognitive science to AI has implications for health-care systems, which are increasingly structured to optimize consumer choice, and for jobs in which the means of production are being displaced by the machine-building machine. AI is no longer merely the sum of the technical advances over the past century, but the direction that which must be driven by the automation of the past decade or so. The transition has implications for the roles and responsibilities of the full range of AI-related activities, from medicine to sales and marketing, from legal to business administration, and from education and training to human-computer interaction.

The transition to AI has implications for the long-term outlook vis-à- vis global economic and demographic change, as well as for many service-sector transitions. AI technologies will play an important role in both the design of long-term global trends and in the design and development of new comprehensive sets of data-processing and knowledge-handling capacities.

The full-scale deployment of AI-enhanced systems will require novel and extremely complex planning and management processes, as well as different levels of collaboration and collaboration between the private sector, private sector actors, and academia. The transition will also require new forms of organizational integration and interdependence, as AI systems are no longer simply integrated into existing structures but are increasingly augmenting and changing the core functions of the organizations involved.

The private sector must take the lead in both exploring and deploying AI technologies. While AI systems are now widely deployed in their generally good design and development, many of them are now becoming tools, capable of transforming the physical world in ways that are not yet understood by their manufacturers. Many more new problems remain, requiring clearly defined engineering plans, detailed data-gathering and analysis, and robustness in anticipation of ethical, social, and labor-management tradeoffs.

Particular attention needs to be paid to the question of automation's adverse impact on worker productivity, as well as the question of whether AI systems have an inbuilt impact on performance. In the case of AI systems, the economics of automation's impact are well documented. The implications are often debated, with some claiming that while advances in manufacturing and information technology can significantly affect productivity, they are essentially non-existent in the applications that people work on these technologies for. As a result, companies are proposing to reduce their workforces, either by replacing or moving to partial or total automation. Both kinds of displacement are
====================
On the day he accepted the call, Biden told a roomful of journalists that he wanted to be a "senior adviser" to Trump. Biden went on to say that the billionaire real-estate magnate needed to put in the work of "team Trump strategizing, data, and movement of an orange lab."

Biden’s work at the top of the Biden clan was heavily involved in the transition. His fellow Bidenites at the time were equally invested in Trump and his presidency. As someone who had spent my entire adult life working to build Trump’s image, I felt Biden was uniquely in my position. I wanted to be that person who understood the American public better than anyone else, someone who could convince them that President Obama was a great man and that Donald Trump was a great person.

But Biden also had a certain fear of change—of alienating the American public. He publicly scoffed at the idea of running for president because Barack Obama was a "sonic president." He told Time magazine in 2014 that he did not have the same values as President Obama but then went on to say, “I think America needs a RINO,” a term he would later change to “skeptic.”

It was in this environment, during and after the 2008 financial crisis, that Biden came to see the unmet expectations he saw gravitate toward deindustrialization. While most Americans had a hard time grasping the idea that large-scale quantitative easing—the quantitative easing that was used to stimulate the economy by the Obama campaign—had something to do with the creation of the “Great Depression,” Biden told Time magazine.

This time, however, changed everything. As The New York Times’ Robert Reich wrote, the “official" phrase was ‘reform”, which meant that the government began to increase quantitative easing, and that in turn, policy coordination began to improve.”4

Reich went on to say that in his study of the U.S. economic “quasi-experiment between 1929 and 1973,” he found that the first official phrase on deindustrialization was ‘a failure mode.’ Even though the experiment was ostensibly started by economists who had studied the effects of the Depression, in fact it was actually launched by a sequence of policy decisions made during the Great Depression.

One might wonder, �
====================
Moves to improve the intelligence quotient are important. A measure of the level of the intelligence quotient ought to be taken as a measure of the level of statistical competence at the particular time and place in question.

A study of 1,001 adults on a general-purpose (STM) supercomputer by Tsinghua’s Cognitive Science Group suggests that those who are more skilled on certain AI tasks are about to be as competent as those who do the work themselves. Those who are more skilled on a particular task also seem to be at high risk of developing the underlying problem. Future work needs to assess the extent to which the STM's capabilities allow it to effectively solve these questions.

Further research is needed to test whether the STM's capabilities would confine it to doing one task at a time and to task-specific competence.

In the field of artificial intelligence, results from previous machine-learning studies are largely understood.3 Some limitations of the present work lend credence to the impression that machine-learning work is completely separate from and is without limits. Nevertheless, similar work in the field of mathematics and computer science has been inconclusive.

In the future, there might be significant differences in the computational capacity (or competence) of a machine-learning system compared to that of a human-level expert system. For example, if the core architecture is more efficient, it could make sense to train a learning algorithm on data that is more competent than a human algorithm, but not on data that is less competent than the human algorithm.

Future work in the field of computer vision and network analysis might also reveal general important new capabilities that are outside of the scope of this paper. However, these are in addition to the scope of the paper to describe these, three other machine-learning techniques, fourth: machine vision via computer vision. Machine- vision is defined as the processing of visual information that outputs to a computer as the computer uses the information to be used to find the location of a target item. Vision is usually thought of as being broadly compatible with vision and therefore cannot be separated into two different categories: visual for general purpose (VMI), say, and computer-based for specific tasks (CBE). Finally, machine-visioning researchers might also discover new capabilities based on the work of other groups working on similar issues.

4.4 Statistics

4.4.1.1.1.2 Aida
====================
Proposal: We need to create a “motorized mobility system” so that drivers, cyclists, and pedestrians are able to use the roads as they see fit. The system will act like a high-resolution map of your daily commute, letting you know when you should be moving by simply tapping the stop sign.

A reminder: We need reminders to recognize when we are getting close. If you have trouble finding a ride on our shared bicycle, please call us at 1-800-MAP-TAKE or 1-800-MAP-TAKE toll-free at 1-800-834-5542.

A safety helmet requires that we make specific accommodations to keep people out. If you are at an accident scene and need to remain on the scene while police arrive, you may need to be able to fill out a helmet assessment. Please include in your assessment the time and location of your stay as well as any hospitalization or trauma. Be very specific about what you want to say to police and fire departments, and ask them to accommodate you if and when you become stranded or need to go to someone else.

An autonomous vehicle-manufacturing company might want to hire crash counselors to meet with employees struggling with relaunching a lost business. Those individuals might be able to provide guidance on rehumanizing a lost business.

Volkswagen has agreed to provide crash counselors to help explain the challenges of rehumanizing a lost business. The companies will use the technology in its automated consumer lending business, and the companies will work collaboratively to create a "zero tolerance" policy for anyone who violates the use of the technology.

But don’t take it from me. There is a lot more work to do to ensure that people are protected from harm in the age of AI, and there are also important ethical, technical, and social issues that need to be sorted out before we can move forward together.

In the past, we have seen both high-profile and less-known challenges to the use of AI. AI has brought many benefits to society, but we still see a long way to get there. Bringing the power of AI to bear on high-risk, high-impact problems that are worth the trouble of solving. While we can expect more of these kinds of challenges to be discovered and addressed by society, we also should see many of the ethical, social, and legal issues that come with AI
====================
The last few years have seen a great deal of attention paid to the seemingly simple problem of turning AI systems that are used for professional purposes into highly dexterous tools that can be easily exploited. In the past year or so, the focus has been on the Chinese market for AI systems. We looked at AI- related products, data, training data, schemas, schemas’ and schemas” and supply chain and distribution, as well as on products and services from eBay to Coca-Cola. In the past few months, the focus has shifted to offering an AI solution to help us distinguish between products that were originally made for us and ones that are coming soon to you. Interest in Chinese AI has increased dramatically, but it remains a very limited and dependent research community.

We estimate that there are around twenty products in use in China today that are directly or indirectly related to one of the major categories of artificial intelligence: commercial real-time AI (brainedcene), business-as-a-service (brainsLNK), or third-party products (ChIP-3, HELix, and HAZARDA’). We also estimate that there are around thirty-five such products in use in China by 2020. The key driver behind this number is the Chinese government’s landmark plan to create a national "Bounty Council on Artificial Intelligence" in 2018, which pledged to work with the government of the Chinese province of Zhejiang to develop "a comprehensive and comprehensive plan to foster the development and commercial use of AI-powered technologies."17 We also project that there are around twenty-five such products in use in the United States that are directly or indirectly related to one of the major categories of artificial intelligence: commercial real-time AI (brainedcene), business as a service (BR), or third-party products (ChIP-3, HELix, and HAZARDA).

These numbers are very encouraging indeed. The market for AI-based products and services is expected to top $15 billion by 2020, and China alone could spend $30 billion on AI-based products and services, more than any other country, according to estimates.18 We estimate that the Chinese government will spend around $15 billion on AI-based products and services by 2020.19 We also think that the focus will be on the third-party components of AI-based products. The focus will be especially on the high-performance
====================
The software is now being sold to hospitals, which are learning how to use it. About half of those who use Uber to hail a cab aren’t using it, a quarter who use Alipay are using it, and a quarter are using it only on personal trips.

Uber has acknowledged that its algorithms can lead to overestimating the likelihood of someone being admitted to a hospital, and it has said it doesn’t have a right to control who gets admitted. But some hospitals, including those in Georgia that received millions in funding from the Medicare program, say they frequently use Alipay and are covered by the company.

Federal regulators last year fined Uber $1.7 billion after it went public under the name Uber New York. That included fines of as much as $15 million and 10 days' jail time, respectively, for its part in a racist driver-assistance program. That lawsuit alleged that Uber drivers falsely claimed their numbers were growing accurately and had contributed to several hundred deaths.

The California-based company has denied the allegations, but Uber New York maintains its system is 100 percent legal.

“We have instituted controls and processes that are protective of our core values and values of diversity and inclusion, and we never influenced or participated in any decisions made or in the hiring process or pricing structure of our drivers’ app or any decisions we make or products or products created by us or third-party vendors.”

The American Taxi and Car Association has also raised concerns about the way it deals with drivers-in-trips. In a letter last year, the AATA called on the ride-hailing company to implement a human review system that would ensure drivers have full rights, including the right to an honest-to-goodness review of their booking, usage, and safety before booking.

“A taxi” is a fairly broad umbrella term for any vehicle that can get you from point A to point B without having to pull over, so this kind of human-driven system doesn’t stand alone,” said AATA president Meg Whitman in a statement. “We agree with the AATA that this kind of human-driven, high-risk AI system should not be in use, let alone promoted, and we call on the company to immediately end this harmful practice.”

The American taxi industry has been under pressure in recent months to provide more human
====================
A writer and freelance illustrator named Mike Cefkin uploaded his first book, The Power of Three Kingdoms: Power, Politics, and the Planetary Pursuit of Power, to the internet in 1985. In it, he described in vivid detail his quest from heISTs, to developing the first print run of the world’s “Three Laws of Robotics: You can't hurt a fly, you can't hurt a quadcopter, you can’t hurt a machine, and you can’t hurt anything except life.” Cefkin’s vision of the world, which is his number one objective, is based on simulated physical laws. In essence, he argues, you can’t hurt a fly, you can only hurt a quadcopter. Power, Politics, and Planetary Pursuit of Power

Cefkin’s Planetary Pursuit of Power philosophy was inspired by Isaac Asimov’s stories about space colonization, and it posited that spaceflight is fundamentally all-or-nothing human’s problem. Humans are driven by three primary motivations: (1) to provide the resources needed to build what might be the world’s most powerful technology; (2) to expand the technological system so that it becomes capable of producing more things that existentially more powerful technologies; and (3) to protect the planet from harm. While the idea of a quest for the three primary motivations may sound appealing to many readers, it is actually quite hard to justify in the long run.

Pursuing Cefkin's ideas, illustrators and illustrators began to see print as a way to probe the limits of their medium and find the balance that would best serve humanity. Image-writers began drawing on and mimicking ImageNet’ing images and then making computer code that simulated the search process for humans. What would become known as the “Humanity Exploded,” became a standard model for graphic design at the highest levels of government and business.

John Koza, the creator of the popular video games and author of the forthcoming book The Company Origins of Me, was similarly unconcerned with how graphic designers were supposed to do their book plays. He simply wanted to avoid the appearance of humans or other non-humanoid forms of life.16 Ever curious as to what some of the most basic building blocks of any company were going to be, he wrote in an April 1948
====================
Eventually, the job of the developer will become the developer of the next job.

John McCarthy (1915–2007; Fig. 2.1), a mathematician and early computer-conferencer engineer, described the development of a new kind of computer: a genie that could play and think independently. As McCarthy puts it,

[T]hat is a step towards creating an artificial intelligence that is sentient and interested in its own work. This is a new kind of work that we can call progress. . . . It is a step that is being taken in the world at large because there are many more important things in the world today than what is in the future. . . . It is a step that we, as beings, have no right to take for granted.

Consequently, we must hope that progress will bring with itparable improvements in intelligence. In the words of the late Ph.D. student of his, Alan Turing said,

The point here is that we cannot expect to be able to walk on the trolley tracks without kicking a human foot. The same applies to having some idea of what is going to happen. We can never have enough of the Trolley. . . .

The human mind is a very important part of the intelligence explosion. It will allow computer science to proceed at a speed not seen since the dawn of man. It will enable us to solve many complex problems. It will greatly increase our collective productivity. It will improve our general understanding of the world. It could even be the name of a better general-purpose tool than the atomic bomb.

Progress in AI is therefore strongly suggested to come from within the AI research community. There are active discussions taking place among AI researchers across the United States, and among industry stakeholders, among researchers working on AI-related problems, and among researchers working on practical AI-related problems. There are also SIGAR (Silicon Valley Declaration) talks, among them by David Chalmers (2012) and Jathan Anand, by Ashok Chaturvedi (2013).

One recent meeting held at Stanford University involved a large open-access meeting entitled, “Artificial General Intelligence and the Future of Life Institute.”12 This meeting, which is open to researchers and not just AI researchers, brought together a broad range of people from academia, companies, industry, and government. It was called the Artificial General Intelligence and the Future
====================
In contrast, the Chinese government has been relatively cooperative in its support of worker retraining and, in the most recent round of international collaborative agreements, has signed on to a long-standing U.S. commitment to provide additional training and oversight for workers in AI-enabled industries.

China’s generous embrace of worker retraining has helped it attract talent, streamline its supply chains, and drive down costs. While the U.S. has not yet ceded the lion’s-eye-1.5 million square miles of territory it calls home, China’s edge in manufacturing and other sectors is a major boost to its image around the world. That advantage has already been translated into 190 million factory jobs, double what it took in the U.S.

As we watched these talks turn into headlines, I worried that the Chinese government would take a serious shot at reining in exploitative labor practices. Instead, I hoped that it would be shot down like a poorly-tuned lead coin. The answer, I worried, would be to accept death as the inevitable endgame.

FOURTH Q&A: Five Unanswered Questions About China’s AI Effort

The headlines from the talks this week were all over the news, with some high-profile cases of workers being hit by robot arms and stun guns. But what came next? Was this the beginning of a new age for worker retraining?

The short answer is: yes. At the forefront of Chinese AI’s minds was the man who went by the nickname “Jack Rabbit.” Initially, Jack Rabbit was just a moniker given to the thousands of workers who were turned into workers by the relentless pace of automation. Since its introduction in 1976, he has remained one of the most popular names in the workplace, with more than 1.5 million employees and a “staff of five.” Now, when asked about Jack Rabbit, the country’s top machine-learning researcher Jack Liu’s Twitter handle is JackScooper.

“Jack, what’s new in the last few days?” Liu’s blog post boasts about how “today Jack was honored by the prestigious McKinsey Global Institute as one of the top 100 most- likely to work in the United States, based on 2020 data, and one of the most valuable companies in the world, with revenues
====================
This is because the brain has no real way of knowing which items we should be paying attention to, and which we should be paying attention to, with the help of visual analogues. So visual analogues are not useful for reasoning; they are just metrics.60 For example, a measure of our fascination with TV shows like the science of digitization might be useful, but not really relevant for reasoning.

The British psychologist Simon Kuznets studied the perceptual systems of monkeys and humans and devised a program to help humans make sense of visual analogues. He studied 150 monkeys and 150 humans, and found that the most evolved display is the most relevant for humans. This finding, he continued, is what gives monkeys their ability to sense "composition: they need to be able to repeat sequences consistent with the contents of the visual field."

To prove his point, he also showed that humans and monkeys could do the same thing with computers – that is, the same thing without attempting to emulate them. This was the real-life dawn of the peopling of kitchens, and it finally did, starting with the Keurig kitchen in MIT in the 1980s.

Unfortunately, the experiment was not rigorously designed, and the monkeys in question were far from human-level, so no experiment was ever set off on the right path. But Kuznets did something interesting – and quite a feat of engineering. He did it by training the monkeys to mimic what computers looked like.

In the words of the MIT press release: "This is a two-day trial of the first generation of the AI system, the Keurig AI, which is a two-day trial of the first generation of the artificial general intelligence. The trial was held in the summer of 1976 at the University of Colorado at Boulder. The computer from the team at the University of Colorado at Boulder was used, in part, to teach the monkeys to read and write. The trial was described by Professor James Clark in an article entitled 'Agnostic Arguments on the Argument from Informality: 2007."'

This is significant because the late 1960s and into the 1970s, when the Keurig AI was being developed, there was a huge hype about the possibility of artificial general intelligence. Now, however, there is less of a "what if" and more of a "when" in modern times. In addition, as we saw in chapter 5, the Ke
====================
“We’re trying to understand the role of the algorithms in this.” “It’s like we are trying to build a city in five minutes”

The biggest difference, though, is that over the course of the technology’s lifespan, the algorithms will be adapting to the environment better than humans. The result, researchers say, will be better, more accurate, safer and more accurate city planning services.

“Imagine if you could just order the entire city in advance and have it order at once by the time you get there,” says Brandon. “That would eliminate the need for a planner. It’s like a city planner is like a robot arm. You can just order the entire city in advance and have it order by the time you get there.”

The same could be said for robots. Researchers say they don’t have any specific plans for when they plan to build new machines. But they do have some general recommendations for how they might someday build intelligent machines:

Robots shouldn’t be required to do their homework. Do not rely on predetermined design principles or set off any surprises. Automation is the secret to whatever interesting breakthroughs have been brewing in the relationship between humans and machines over the past few years.

Considerable scientific restraint is required in order to make sure that unexpected twists and turns result from design choices that may have unintended consequences. That may be reassuring for those who feel that their faith in AI has been completely misplaced.

The era of self-policing, though, is long past time for that kind of self-policing to become more widespread and widespread enough that we can all step aside and allow the process to finish.

The seeds of that process will be sown in subsequent years, when greater and greater amounts of data will be required for intelligent systems to perform their own self-improvement work. That extra processing power will then enable machines to do so much faster and more effectively. As AI becomes ever more powerful, it will be necessary to beef up the amount of data that is required for intelligent systems to perform their own self-improvement work. This will require a shift from one sector of the economy to another.

One of the more important advances in AI in terms of its impact on the global economy is the transfer of manufacturing power to the developing world. Manufacturing has received
====================
“Chinese companies are putting their best foot forward to compete with the world”—but what they’re doing is upended by a new generation of internet-driven entrepreneurs whose mission is to reimagine the world and break new ground in computer and software engineering.

This is the second part of an eight-part series profiling the different strands of the “New Economy of Computing.” It explores the underlying economic and social imperatives driving this explosion of computational power, the internet’s role in this “crowded computing universe, and the ways in which this has transformed the economy of the digital world.”

Part one: The Promise and the Trap

“We’re in a strong position right now to make the technological leap,” says Wang Xing, chief innovation officer and cofounder of Palo Alto Networks. “We’re in a good position to make the next step.”

Palo Alto Networks founder Meg Whitman acknowledges that “it’s always a little hard to say it all,” but she agrees with Wang’s assessment of the strength of the Chinese company. “It’s not just one Chinese company. Every company has their own challenges and they have to solve them.” She agrees with the sociologist Achille Mbembé who says that “the Chinese market” has “trampled for a long time.”

Part two: The Promise and the Trap

The truth is, Chinese companies don’t just find ways to make faster computing chips at a fraction of the cost in other markets. They also don’t just run ads in local media to convince themselves and millions of Chinese people to move to cities like San Jose, Beijing, and Shenzhen. They’re actively planning out these kinds of cities and other ambitious internet-connected projects.

In the words of the author Kevin Roose: “You will see ‘digital India’s' emergence as a ‘world leader in internet infrastructure’,’ as the ‘Internet of Things’ that are driven by smart devices.” In the words of the MIT Martin School: “It’s not just cities that are going to benefit from ‘digital India’s’ emergence as a world leader in internet infrastructure.”


====================
“TripWise” is the name given to the popular app, which learns the most about you using a smartphone. The premise is simple: you may be walking down the street, in a city, an average person is walking by, and so on. The app uses a combination of deep and shallow learning, real-time, data-driven, and weather-based analysis. The closest you get to a specific street is a “name” and “type” levels, based on distance and date and time. TripWise then uses those as inputs into a learning algorithm that updates its estimates of your closest landmarks in the shortest time.

The app is not without its critics. Self-driving cars are known to be a nuisance and are projected to be an increasing number of drivers. But the trip-taker app has gained such a following that it has exceeded expectations. More than 10 million people have signed a Kickstarter campaign to buy TripWise, and over $1 billion has been invested so far in the startup.

Why TripWise? Because the human-level model is less likely to think it’s an automobile problem than a human does, and it will be less tempted to try to solve the problem by mistake. Humans, by contrast, tend to be more analytical and less likely to try to solve problems by themselves. So why not try an AI version of TripWise?

To explore this hypothesis, we need to understand a bit more about how we arrived at this idea.

The initial idea

Back in 1999 I described a small app called Mocha that used deep learning to model traffic lights and asked what percentage of the time it was raining. It found that the actual volume of the rain was much higher, but it’s much more difficult to predict the exact volume. The app’s “prediction” was that I would be the heaviest person in the neighborhood.

Fast-forward to this week, and someone at Google says “it’s raining heavily in Seattle. Let me calculate the percentage of times drivers in Seattle must be in Seattle to be allowed to drive.”

The answer, of course, is no. It’s raining heavily, and the city of Seattle is absorbing a bit more than the typical resident of Seattle. So the typical user of Google’s Gmail gets about 10 percent of the volume
====================
THE MOUNTAIN VIEW, British Columbia: AI labs have been experimenting with the technology behind the showroom ceiling: visual recognition software called Siri.

Researchers at the University of British Columbia have developed a suite of automatic and social features that can recognize a caller's voice without a camera in the room. The software is more intelligent than a traditional face recognition system, said Sam Altman, a professor of computer science and a professor of human-computer interaction at the university.

Using the software, people can easily recognize the software features by leaning on them, waving them, and shrugging their shoulders. It can also perform a face-recognition of the person speaking to Siri, said Altman, who is also the director of communications for the Face Change Foundation, a non-profit organization working to end computer face-recognition research.

Siri is the latest voice technology to hit the market, and it represents a major shift in how people are able to access the world around them. AI applications that relied on face-recognition have suddenly appeared in the past year, said Andy Stern, an operations manager with Manhattan Institute on Financial Fraud Investigation (MITFIF), an organization that probes financial crimes.

The MITFIF report, which was released last month, asked for input on the need for AI labs to enable the use of face-recognition technology in "fraud detection and mitigation." The agency has been working on this for two years, said Altman, who is also the project's technical lead.

Now, instead of just relying on static images or sounds, it’s needed to understand the technology better, he said.

I envision labs using the technology to develop self-aware “probe-people’s breathalyzer.”

Stern believes labs that use the technology to help people avoid identity theft can also play a role in policing people who use social media.

“Law enforcement should think twice before using this, because it could turn into a surveillance state, and it’s easy for it to become something that people associate with something more nefarious, like organized crime or Al-Qaeda, or things that could be used to kill citizens, he said. “It could be used to try and avoid detection, because you could be sure that someone is going to find this stuff, and it’s likely those kinds of things.”

He
====================
In a world where augmented and virtual reality are becoming more widely available, what does an augmented person need to do in order to experience augmented reality? They will (eventually) need to make certain mental and physical accommodations to be able to experience augmented reality. I discuss some of these in the book A Brief History of Human-AI Jointness, which you can find here.

First, a quick history of how we came to think of virtual reality as part of the field of virtual reality, and how we came to place it in this context. During the summer of 1966 at Dartmouth College, I had the pleasure of attending a summer internship with the neurophysiologist Seymour Papert, a brilliant philosopher and neuroscientist. (I should come as no surprise, then, that Papert had no problem in teaching me how to code!) I was staying at an apartment on the campus of the University of Massachusetts Amherst when he came to visit. I was staying at the time a "visit for a professor from the university’s department of physics and computer engineering" – a department that he was trying to attract. He showed me around the converted shipping container on the city’s south shore and gave me a tour of the building.

He had me up on a high scaffold and up close. The first thing he saw when he came into the room was a huge scanning computer with an antenna on top. He also showed me around the lower level of the computer. He said that I was the man who designed the program that would measure the brainwaves emitted during a simulated brain-surgeon visit. I told him that my goal was more than likely to be a yes-or-no yes-yes question, with the patient in the next room to answer.

“He was going to blow your mind,'” I told him. “He said yes, please come with me.”

I was in great spirits. I had just completed two years of graduate school, and it had been a pleasure to spend one of those years working with scientists who had given me the chance to share their knowledge with the world. That experience had taught me to never, ever, ever, ever let anyone tell me, "You know what you’re doing when you’re having a real conversation with the brain-surgeon?”

He smiled widely. “I suppose you could say that
====================
The same principle applies to other types of AI systems, such as machine learning algorithms or machine-learning models. Some AI systems, such as machine learning, also have some role in politics. The United States has become a strong case in point. As a country, we’re among the leaders in this area. China is—as the market research firm Didi has discovered—among the countries that have the highest proportion of digital transactions with government entities or companies with the power to block or modify these digital transactions.

Blockchain technology could change all that. It’s currently only available in Japan and South Korea, but if adopted in the United States and China—and in many other countries that have joined the fray—could dramatically accelerate the creation of new and stronger AI models. This would give us a major leg up over the competition and perhaps further boost the “AI superpower” status of the United States and the United Kingdom.

But in the end, it’s the sheer scale of possibilities and sheer power of AI that really gives these two countries and the rest of the worlds economies hope. With such an expansive horizon, why not experiment with an entirely different approach? Could we not build this technology as a niche product in a larger social and economic ecosystem, one that genuinely benefits all?

The answer, of course, is that there is no market for it right now—more so’s the pity factor—so we need to build it as a service economy. That could mean following our locales, visiting our local hardware stores, or spending a little time around our local labs. The last possible use case is in its sense a micro-finance transaction—a quick fix to a problem that might otherwise have gone away. The same goes for building a super-intelligence: building a super-appellation seems like a very small step compared to what's possible with the underlying technology. But building a super-appellation also requires that we build superpowers for the humans: a strong AI could be able to conquer the world, take control of Earth, and implement economic reforms. It’s a bold but not unprecedented idea, and it could turn our entire economy.

This all sounds very possible, but we have no doubt that the time and resources required are vast. We need a savior to get there. The question, then, is not whether we could get there by hijacking existing technology—the question
====================
It looks like Google will soon raise the bar for AI in artificial intelligence from the very first iteration of the AI family. In doing so it will broaden the existing capabilities of the AI family and push the bounds of what was possible before.

The promise of AI-powered products and services is clear: We already have enterprise-level solutions that can help us automate more quickly, and those solutions are now replicating the power of the internet-based services that emerged there. Google, Microsoft, Amazon, and Facebook have all announced plans to offer AI-powered products and services.

But what will these new possibilities of AI look like on the shelf? How different will these products be? Will they be products you can take with you when you get to university or are ready to dive into the next wave of AI that will usher in a world revolution? Will they serve as your personal scaffolding as you build AI-driven companies? Will they simply replace your digital footprint as you run your business or are ready to transform your entire workspace into AI-driven services?

A Brief History of AI

The history of AI is long and complex, but the basic premise is simple: the task at hand is to get someone to do something useful for you. Business has already done this before, and it continues to do so as it accomplishes new milestones in AI technology. As such, the phrase "AI for the people" is often used to describe these services that augment the functionality of existing processes. However, the actual building blocks of AI are still largely private AI systems—not state-of-the-art AI engines or complex algorithms that perform various machine-learning algorithms only the software developers had in their datascape.

Consider the non-profit that works on behalf of victims of human trafficking in Belgrade, Serbia. In 2018, Google released its version of ZestFIND, a search engine that would enable it to trace victims' sexual orientation, familial status, place them on condoms, and even schedule sex parties.44 The technology was meant to help people avoid contracting the harmful diseases that afflict many victims of trafficking. The goal was to help the company "reduce in Serbia by half." But in a surprise admission, the company's website boasted that it was “devoted exclusively to the humansexual side of life.” It wasn’t until later that the focus became to robots. After admitting that “robotization�
====================
About us: The Consolidated Company of America (CAC) is the premier provider of consumer-based services to consumers through CAC's online education platform, www.CAC.org. Our extensive experience in the consumer-facing context of our products and brands has enabled us to work collaboratively with partners to extend our expertise in education and marketing to offer consumers a more tailor-made education and training platform for critical industry skills training and development. Through CAC's extensive training and development staff, we have been able to develop and expand both the learning environment for our loyal customers and the platform for their leading edge technologies. Our extensive training and development infrastructure includes leading-edge technology-infused companies with proven track records in education and research, experience in digital transformation, and strong track records in consumer-facing product and brand building. We also have extensive experience working with leading AI companies like Google and Facebook, as well as those of traditional business intelligence companies like IBM. In addition, we have extensive experience using third-party vendor training and development tools that provide a comprehensive, machine-checked education and training framework for leading-edge AI systems. Our proprietary, grade-separated AI training sets are designed to be tailored to each consumer's unique needs, and they can be used in tandem to develop and train AI models for the following: Natural Language Processing: 90% of CAC training sets are tailored specifically for natural language processing (LLP) use, with the remaining 25% coming from third-party vendors. For these types of businesses, training and development costs are typically well below the retail price of a typical commercial product, which is why our training and development teams work with more traditional vendors. We provide consumers with direct access to expert training and development support as they explore the different options and choices within CACs online education platform and on-line platform.

Consultation: 90% of our professional and personal representatives serve on our 31,000-member sales and marketing team. Our team members are trained, experienced, and willing to discuss ideas and approaches to potential collaboration opportunities with you-towards-the-art products, services, and processes automation. Whether you're seeking advice on how to get a product or service from the company, or are looking for an expert opinion piece that explains the business's unique strengths or weaknesses, our team has the expert advice. Our team members are also trained, experienced, and willing to discuss ideas and approaches to partnering with you
====================
”

This book is not about “the magic of AI” or “the frontier beyond AI.” I think many readers will disagree with you. On the one hand, you’ll be reading stories about “the work of AI,” the technologies that can improve our lives, such as self-driving cars, enabling people to work more hours and taking us longer. On the other hand, we’ll see that these technologies are not as “smart” as we think, but they are not as “stupid” either.

For example, self-driving cars can be programmed to perform tasks you would find yourself doing only by yourself, such as walking, running, gardening, and hunting. While you are doing those tasks, the car automatically assumes you are doing them safely, because the humans are using your car as a personal body scanner. You are not seriously hurt or harmed by these autonomous enhancements.

Self-driving cars are not “impaired” using these optimizations, because they are not fully autonomous. They may be partially, but they are not fully impaired. There is no harm done to you by them. You can have very limited mobility by driving with fully equipped cars.

“You just have to pick and choose what you want to do,” Mr. Kurzweil said. “You can’t ever do any self-destruct. You can just pick the car that’s going to go first, and the car’s going to go first.”

The real problem with that argument is that it assumes that there are any limits to AI. I think that it is a mistake to assume there are. The problem with that assumption is that it overlooks the power of optimization over sub-human capabilities. It assumes, for example, that an AI can successfully complete tasks that you would not think of asking such a machine would complete, such as picking a flower from a bush without first lighting it with a flashlight. That is not possible. An AI can, however, take the actions that you would consider to be potentially very dangerous, like being attacked by a rabid dog, because that would require the dog to have a greater vantage point relative to the human dog.

What you are saying is that an AI can be very good at certain tasks, because it has a baseline level of general intelligence
====================
Looking for news you can trust?

Independent news is more important. Sign up to get the best of The Nation delivered to your inbox every weekday. You will receive occasional promotional offers for programs that support The Nation’s work. See your support America’s legislation today.

Thank you, Firstpost editor-in-chief Nathan Myhrvold, for bringing this issue to my attention. As a lifelong New Yorker, my family and I are all immigrants from Czechoslovakia, and I am always looking forward to the opportunities across the Atlantic.”

Myr Martin said, “I think it’s important that we move away from a view that’s “nervous” and instead focus on concerns about the environmental, labor, and health impacts of nuclear energy.” “The question is: Do we really want to be in the habit of thinking that way?”” “The question is: Do we really want to be in the habit of thinking that way?”

My response is simple. I think we should move away from a belief that we’re in a race to the bottom.” I think we should move toward a mindset that leads us to suppose that any resource that we extract will make a large difference to the fate of the human race. That is, if we can convince ourselves that it will at least in part (a) make a difference. That’s because the conditioned reflex—the idea that we’re in a race to the bottom—can lead us away from a realistic prospect of using a resource when available, rather than toward a fantasy of using something else if it becomes unavailable. We need to shift our outlook from something that’s cheap, easy, and definitely something to scare ourselves away from.

My response to that is two-pronged. First, I think it’s important to convince ourselves that we are in an advanced phase of this technology, when we’re investing in our future generations with real money—in other words, our own money. And second, I think it’s also critical that we shift our economic and social incentives toward scarcity.

Let’s face it: We’re in an age of abundance. The world is finite. Too much technology can degrade the quality of life of billions of people around the world. Over
====================
DARPA’s real-time AI systems are used to flag suspicious activity at border crossings. But the system, which uses AI algorithms to identify people crossing at dawn and sunset, fears border agents may be “stupid” and wants to stop them.

DARPA’s AI systems are at a near standstill, less than two weeks, as U.S. authorities consider possible new high-profile cases of human outsourcers over the summer of 2016: the arrest of Alex J. Trebek for attempting to board a flight from Seattle to San Francisco with false ID. (See Fig. 2.7.)21 But to win over the D.C. bureaucracy, officials had to rely on a combination of public shaming and public relations firms to keep up with the growing wave of automation.

As it turned out, J.D. Salinger was just one of many people using AI to inform decisions on behalf of American workers. In 2017, Yahoo! sent a letter to its global sales and marketing team claiming that the company had activated part of its algorithm in “firefox” users who were trying to enter the United States.22 But the message was essentially the same as in the original letter, with Yahoo! claiming that any attempt to enter the United States would “reasonablybe classify as work and therefore deserve to be compensated.”24

AI systems are taking center stage at hiring. The typical stage of a new technology’s development is its evaluation of human judgment and performance. And firms are taking it as a sign that AI is starting to share more common traits with humans in the workplace.

At Microsoft, for example, when we met in 2005, senior vice president Bill Gates called our meeting “Morning Joe,” to mark the occasion.

Bill is a brilliant young engineer with a sharp sense for what makes a company tick. At the time, Microsoft was trying to build a computer system that would match those of its Silicon Valley peers at identifying suspicious activity, keeping tabs on people, and doing what little hardware was possible to do. So instead of going into production mode, Bill went into production and captured the surveillance camera and other tools needed for AI. In the process, he created Al, a software program that acts as an agent of the future.

Today, as Al systems like Bill’s are deployed at work, the future may be at hand
====================
Analysts say the AI tools are helping to seed a new era of collaborative and symbiosis among workers in both sectors.

"The fact that they're helping to develop this new paradigm in the global supply chain is a really big step," said Jack Clark, an operations professor at Carnegie Mellon who studies labor and labor peace in the software and services sector.

The companies that have made up for lost time by enabling workers to switch industries are Amazon, Alibaba, Tencent and ByteDance. But these companies still face the challenge of supplying workers and training them for the next shift, said Yuval N. Li, chief executive of O2O service provider O2O 360, a San Francisco start-up that purports to deliver "human-to-machine (H-L) education and training to workers about the importance of adaptive management and the importance of high-quality work experience."

Tencent has taken the lead on that front, using O2O to train its R&D team on the basics of H-L education, as well as offering training courses and resources for workers in its R B-1 programs. Mastering one H-L element of O2O is like taking second-year higher-level computer science courses, said Sam Altman, the company's CMO and a pioneer of the technology. Tencent has already established training camps for its R&D teams in eight Chinese cities, and each one has thousands of participants.

ByteDance's training programs focus on workers completing "eight- to nine-hour shifts, building skills that can help students in the supply chain, said Zachary Holden, the company's CMO and a pioneer of H-L education. He described the training as "groundbreaking," and he expects the total number of O2O training jobs to double to 1.7 million by 2020 . "

Tencent's training programs are tailored toward training workers who are most at risk, and the companies aim to deliver on the promise of H-L across the supply chains, Holden said. "We think it's going to be killer," he said.

Tencent has trained around ten thousand workers so far, and it plans to hire as many as 1000 new jobs in the coming months, said Melissa Heikkilä, Tencent's CMO and a member of the Swedish Council for the right to Education. The company has also created a training institute for workers who need
====================
I have been relentlessly pursuing AI education for the past four years and have had no problems convincing my parents that I had read and understood the basics of AI. I have even given lectures at universities about teaching AI and have shared the stage with audiences about making machines learn. I have not turned heads either. In fact, I have almost no idea what AI is.

Many deep learning conferences and workshops are nothing more than a romp through the “vulgar imagination” of AI researchers bent on making machines learn. I am one of these "imitation practitioners,” who believe that any time there is a new technology that can solve a problem that is previously unsolved, it is going to be highly desirable to have a clear path to solving it. In other words, if you can get a realist or a theorem proctor to actually write down the steps from zero to Solvable, it is very easy to get a solution to a problem.

This is the typical state-of-the-art for the field: done, done, done! This fantasy has created a climate of fear, as talk radio and Wikipedia articles have been written about AI. Deep learning is widely seen as something that can be poetically solved by hand (Figure 3.1), but there is considerable resistance from the field to doing so. In fact, several leading AI labs, like Google and Microsoft, have stated their opposition to doing so. (See Figure 3.2.)

The field of vision is steeped in the ideology of science and technology, which is to say it is steeped in the conviction that everything can be measured by small steps, fixed effects, and that whatever is worked out in one laboratory can be made up again in another. The result is what sociologist Karin Knorr Cetina terms the “universe of small steps, fixed effects,” that any given problem has a “significant” and linear “lens lock.”21 At that time, matter, energy, and consciousness were still unknown, and there was no clear way to describe how problems should be solved. Now there are “large step” problems that are solved in the same way, just by a different approach. Because the universe is small, linear” problems are much easier to solve.

The physics of movement are also known as “room-temperature” phenomena, because they can vary in density and
====================
Productivity growth rates in the late 1960s, early 1970s, and early 1980s were similar to or greater than historical averages. However, during the great productivity-discounting campaign in the 1980s, falling productivity actually started to decline rates of change, leading to falling unemployment rates. Since then, rates of change have returned to their pre-discount rate, although in different ways. For example, during the late 1970s and early 1980s, the global demand for labour fell; indeed, much of the fall was caught by data- vendors or consumers, leading to soaring unemployment. Since then, however, rates of change have returned to their pre-discount rate, although it is likely that this effect has waned somewhat. For example, in the early 1970s, when the effects of the 1970s and 1980s were most intense, real rates of change in labour market rise were similar to or greater than historical averages. Since then, however, rates of change in labour market change have returned to their pre-discounted level, although it is likely that the latter effect has receded.

Productivity growth rates reflect the pace of improvement in a given technology set (or lack thereof). Technological developments speed up the pace of technological change. For example, the speed of Moore’s Law of accelerating advances in computing, data, and machinery is the main reason why prices of electricity were between two and three times higher in some countries during the late 1960s and early 1970s than they are today. Perhaps more importantly, Moore’s Law of accelerating technological change is the only true measure of the progress of an economic system that can be taken as an indicator of the success of its leaders. Technological change is measured not by its own speed, but by the measures taken during it. And as rates of change higher, so do technological innovations. Rate-setting technology, which makes an economic system more efficient by changing the rate-finding process, is another reason why inventors and technologists tend to be slower to invent.

One cannot predict the future with 100 per cent accuracy unless he or she has been able to identify a set of patterns or general improvements that will become prominent in the coming years. The only way that the next 100 years or so of economic growth can be accurately forecast is if we have the right sets of general improvements. If we don’t, then we get dystopias. If we do have a set
====================
A man who took part in a GoFundMe campaign to rid his country of the unicorn horn thought he had found a cure for an annoying bug, but instead turned out to be a terrible person.

During a trip to Japan this summer, Justin Ney was inspired by the work of the Go Fund Me Fund Me campaign, a Japanese GoFundMe page that raised over $60 million for endangered unicorn horn. The project aims to raise money for endangered hornponies through dividends and intangible human-kind proceeds. The project is largely funded by renting acoustic utensils and other equipment from the animals, and distributing the proceeds to people displaced by the discovery of new technology.

But after a visit to a major corporation Japan in the early hours of the morning, Ney was speechless. In his prime, he was a goofy idiot, but his spirit was strong. He set out to make a difference, by creating a GoFundMe page for endangered horn.

The response from the page was overwhelming in the end. Over 3 million people have responded to the page, and several hundred companies have responded with products such as “The Voice of Japan,” “GoFundMe,” and “SAFEbeach.com.” The response has been so overwhelming that several companies have sprung up to match the needs of captive animals.

But the most popular of these is SAFE, a Japanese company that makes GoT-enabled smartphones that can predict the beat of people and train people to take the place of Siri in everyday life. The company doesn’t claim to have invented the technology behind Siri, but it does a fantastic job of showing off the phone’s abilities: the glass is glass, the horn is horn. For these impressive toons, Go is a game between typing and swiping, and they can take down any app that might have attempted to “talk” them.

Another good one is Koko, a Japanese company that makes software that helps people find each other using the search function of their phone. The company has more than 1 million registered users, and it already knows a thing or two about each person’s search status. From a user survey, it found that 88 percent of them identified as having used Go and 88 percent were interested in trying Koko software.

The success of these companies points to the power of engineering in general—the ability to engineer problems for
====================
In April 2017, the Dow Jones opened lower than the previous week’s average, falling 0.4 percent in Japan and 0.5 percent in China. The index moved under the US treasuries from a new low of 2.19 percent in October 2013 to a new high of 2.16 percent in China today. Thereafter, it recovered as low as 0.3 percent in value.

But I would predict that in 2017, in all its rainbow of colors, the Dow Jones would fall much further than it had in October 2013. Since then, it has recovered somewhat, recovering only 0.2 percent in the US and 0.1 percent in China. However, I do not expect the index to fall much further than the 2.19 percent range that we have seen the Dow Jones index currently is set to rise on, assuming it remains above that level for long.

Historically, the Dow Jones went from being the largest single investing IPO to the largest never held by an IPO. I am confident that in 2017, pent-up demand for digital and advanced products will diverge significantly from those who seek to purchase. These differing tastes in the diverge dramatically. Some people like to see the Dow Jones as the savviest investment, while others see it as the most valuable. I won’t name names here’s for both camps, but I will speak of “high-end” and “premium” investors: those who want something different from the average.

Here is the purest example of what I would call a “premium opportunity”: a novel idea or application that could drive a great many new users:

The story of the “premium opportunity” is simple. A niche has been created for an interesting new application developed by a startup. The startup’s founders created an innovative and unique product, and in doing so they turned a profit. But the market has not come back for the founders, who are now kicking the can down the road. The marketplace has failed them, and the product they poured their heart and soul into has failed them all.

If you believe that markets are finite, then this example serves two purposes. First, it lays the foundation for how to build new empires. Second, it lays the groundwork for AI-driven companies.

First, the market’s failure to provide an innovative product
====================
HERE, THERE, AND O2O EVERYWHERE

“The computer is the basis of all life,” says Mike O'Malley, chief information officer at O2O Ireland, an umbrella group that advocates for the inclusion of open source software in Irish education. The idea of AI for the education system derives from the ancient Greek philosopher Aristotle, who identified AI as “all-embracing, all-creative,” while “AI” is Latin for “work-creating,” O2O. The academic distinction is from Google’s DeepMind, which was known for its role in virtual reality.

O'Malley acknowledges that “the AI community has been sort of mincing away at the edges of things, blurring between the academic and commercial worlds for years.” But he says this shift is not unprecedented. Back in the late 1970s, when giants like Microsoft and IBM were building AI products, the real distinction was made making the phones that sold for a certain price. Now it’s all about localization: “With the internet, it’s easier to make a phone from scratch,” he says. “But now you can actually make a phone without leaving the internet.”

“Suddenly, you can actually build an entire city in one go, without having to dig deep into the city-state,” says O'Malley. It's a shift that has profound implications for the health of the internet, which was once something like an arm’s-length relationship, says O'Malley. The phone revolution marked a new low for internet innovation, he says, “it was like throwing up a bridge over the internet.”

AI fosters both learning and speed of access

Larger cities and the internet’s other cities are often built on the shoulders of giants. So how do these other technologies—from AI to speech detection and analysis to machine learning and deep learning—affect us as digital agents? How do we best use AI in the context of these different places, places with varying levels of infrastructure and access to different kinds of people?

Larger cities are good example of the other AI-rich regions of the world: the lowlands and the rain forest. Those places are generally not thought of as destinations in a rich digital world. Instead, they are often viewed
====================
Sections on Workforce Development

What are some of the areas where AI can augment human capabilities? AI has made it possible to build companies that are more flexible in how they hire, fire, and collaborate with business partners. While early attempts to do this by using reinforcement learning had mixed results, companies like Apple have proven that using AI to its full potential is possible.

In particular, the company has excelled at attracting high-end talent to the company, both in the past and present experience, and it's proven adept at attracting small- to mid-level talent. And whatever those talented people are doing, it’s impossible to know precisely how they might use AI to improve their work processes or interpersonal skills. In many cases, AI is just a tool for improving their ability to do the things they do best: a high-flier, for example, might not necessarily translate to better results on customer service or persuasive technical leaders. And, of course, there is no guarantee that a machine will respond with enthusiasm or compassion or carry a high level of competence when asked to explain the workings of a business or how a business should be run.

But there are other areas in which AI can do what many humans can do—and is already doing—that bear some sort of more conceptual resemblance to human capabilities. Take, for example, the way AI can recognize patterns in data. As discussed earlier, AI can model the actions and reactions of highly skilled workers, and it can do what many humans do well: identify opportunities and make decisions accordingly. And, as discussed earlier, AI has already made it possible to build highly adaptable businesses from the ground up.

What about work in the field of medicine? Many of the products and services being offered today—including AARP's popular CrossFit rig—are already highly adaptable, customizable ways for professionals to train their bodies. Combine this with the fact that most people can already train and act physically, and medicine is showing remarkable progress at keeping up with the demands of the market. While it remains a challenging and often wrenching business, companies are finding ways to reimagine their business models and meet the increasingly demanding behaviors of the evolving patient.

The future of work is clear. AI is enabling true innovation and reimagining our daily lives. It is also creating opportunities for the emergence of true humanists, people who care deeply about the many ways they and other people like me can work
====================
A man who lived out his one-millionth birthday as a devout Christian has made an unlikely career after death.

Kevin Ware became the world's most wanted man after his arrest in Germany for fraud, Fortune reported. Ware is survived by his wife, Alice, and two young children, Kevin Goldfarb and Sophie Deeb, the report added.

“I believe in destiny, people want to be noticed, they want to be noticed,” Ware told the newspaper. “People want to be recognized,” he said, “and I think that those values and those intentions have translated into the rise of Kevin.”

He left behind his wife, Alice, two young children, and an online dating app. Ware moved back to Germany and founded Heimdall in 1994. After a successful one-year stint as a software engineer at a state-owned bank, he moved back to his San Francisco 49ers jersey and worked his way up from cofounder to CEO. The company eventually went out of business, but not before becoming one of the most valuable software companies in the world.

Heimdall went on to win the first Google Ph.D. in 2001, a prestigious one for a man who wears the company’s logo on his chest.

Nowadays, Ware lives in California with his wife, Alice, and four children, including a daughter, Amy. He is known for his ode to music and the small screen, and his 1995 autobiography, The Firstborn, which opened the New York Film Institute’s Lidl.

He doesn’t like movies.

“I prefer movies. They remind me of work. It’s just a bit more clunky.”

He recently completed the 100,000th movie frame, directed by John Ford’s John C. Reilly. Ford had previously directed Ray Bradbury’s Peter Pan and 2001: A Space Odyssey, among others. Ware’s 2001 movie is the first to receive such an appreciative ode.

“I don’t like being called a movie star,” he said. “But I like working on a movie screen. That’s why you see so many sci-fi movies. Because they have this weird thing called artificial intelligence that thinks twice before letting you make a movie.”

====================
Proprietary software was the new gold standard for creating computer-friendly AI, but many of its shortcomings still loom large. While the first wave of GPT-4's problems centered on unanticipated behavior by programs, the following wave, which displaced GPT-4, tackled much deeper problems. Initially, the solutions were just shy of satisfactory, but over the course of a decade of development, improvements in LLMs, R&D, and customer support, GPT-4 became the standard. And so it continues to this day.

But GPT-4 is the official standard, and for good reason. The next generation of AI has proved to be the most powerful and reliable, and in many ways the “gut trigger for the next wave of transformation.” The story of GPT-4 goes back at least as far as Henry Ford is able to tell us about the ignition key.

Let’s begin with what GPT-4 can do. It does what it does best—spotting opportunities for an unintended A, generating tens of millions of false positives, pulling false positives off within a minute, and correcting errors that could have been the work of others. It has the ability to answer questions concisely, and to respond to both prompts and documentation. And it has the ability to scale up and down its engines so that it speeds up and decelerates in spectacular displays at speeds that leave no inch of wasted energy.

It has the ability to create highly optimized code, much of which is irrelevant to the task at hand. And it has the ability to generate original, high-quality programs, much of which is irrelevant to the execution of the programs described in this book. Even when GPT-4 doesn’t do anything at all, it can iterate over millions of positions and produce highly optimized code that it can then immediately execute on top of, eventually, the first problem. That type of performance is what sets GPT-4 apart from the competition, and it drives a real competitive drive among AI companies.

GPT-4 isn’t just a technology that can do one good thing: it isn’t just a technology that can do one great thing: it isn’t just a technology that can expedite the development of one good idea. It isn’t just a technology that can expedite the development of another good idea. As we will see
====================
AI is not only enabling the creation of superhuman humans, it's also changing the planet. Scientific research into neural networks and machine learning is beginning to confirm what we had been saying for decades: We are on the verge of creating a machine that's smarter than the human race."

— Elon Musk, Musk Foundation

The verdict? The age of prediction is upon us. We're on the verge of bringing the age of prediction to a close, and we're going to have to do it faster than any human – not just the current one, but multiple others, experts said.

That's because AI is not only helping people become smarter – in Musk's words – it's also turning the clock on in the human race's cognitive war for power. The clock is turning on in the race, and it may soon start turning back on already-disrupted markets like Facebook and Twitter.

The latest skirmish between tech giants over dominance in the age of AI kicked off in 2013 when Google and Microsoft won a battle that pitted the giants against each other. In 2014, Google and Microsoft both introduced neural networks to the market, but after several complaints about performance, both companies decided that the time it took to create a model was too valuable to pass up.

In 2015, after months of back-and-forth with Microsoft over performance, a federal judge in California threw out one of the giants of the internet's largest internet companies, blocking access to more than a million internet users. That ruling triggered a three-year-long battle between the companies, which now call it Tensor Valley.

The battle for dominance in the social network was not without its fair share of casualties. Google and Facebook used AI to fine-tune the algorithm for driver-sharing platforms like Uber, while Mechanical Turk used deep learning to undercut that company’s competition. And Facebook used the same technology for several months to Make a Deal, an arrangement whereby Facebook would initially sign on with TensorFlow but would pull back after 10 years if it was proven it was working on AI-backed AI.

But the battle for dominance in the age of AI has more than paid off. AI has allowed internet giants to reimagine their business models and undercut competitors, and this has not been without its fair share of casualties. Google and Facebook have surpassed their competitors in terms of data and processing power; their users are finally getting what they paid for; and their algorithms have grown
====================
“The biggest mistake that I see people make is going after the evidence that they don’t know better” “The biggest mistake that I see people make is going after the evidence that they don’t know better” “The main thing is to have a really solid argument that doesn’t boil down to red herrings.”

The American people deserve to know what role automation plays in their lives and what technologies can foster more successful, responsible, and beneficial decisions. The American public deserves to know what technology does and when, what impact automation has on jobs, and what “technologies” can and should impact them. The American public deserves to know what technology should look like in its entirety before making decisions about whether to adopt or adopt private investments.

In the past few months, I’ve shared stories about how startups like Piney Wood, Smart Finance, and Blueprint for the Future have helped people who are having trouble finding credit, loan approvals, or credit monitoring. In those instances, the federal government has helped these startups navigate the rigors of global competition, private lenders helped them expand their business, and government controls helped them dodge some of the most treacherous turns.

But there’s a far greater problem with this data-driven approach to policy: it assumes that there is no correlation between the abundance of data on prices and how much control these sectors have over economic decisions.

To see that stark contrast with traditional American economics, I joined a growing number of leading financial companies this summer to announce publicly-funded demonstrations of how their products could reduce foreclosures and stabilize prices. Among the first: Palantir, the darling of the American financial industry, a multimillion-dollar defense industry company that makes flash-cards, short-term fixes, and autonomous trucks. All kinds of flash-cards, from credit ratings to mortgages to YouTube videos, are preloaded with information. The goal is to approve transactions when a phone or laptop data signal captures a moment in time, and Palantir secures key details of those transactions with a trove of terabytes of real-time data. Payments are encrypted through apps like Alipay and ZCash. And as you can imagine, that makes for a very, very nice, timely payment.

But Palantir’s products don’t simply automate the process of applying for loans. They enable consumers to make
====================
“What does it mean to be human?” “It’s a complex question, but one thing that I think we can all agree on is that we’re all better off as digital beings having more say in what the future holds for us.”

Might this be worth it? Could we at least steer clear of the default outcome scenario in which we end up having to choose between two humans instead? It is a question that we should consider, not as an option, but a must, says Kaspar Hucock, Program Director of the Future of Life Institute at Duke University in North Carolina.

Even if we reject the idea of anthropomorphizing the future as an option, it would still place an enormous strain on the existing incentives for AI, says Hucock. Humans are still the ones being rewarded with hardware that can make smarter decisions, he believes. “It just so happens that the human brain is the largest single conceptual animal in the world,” he says. “So given the importance of that particular conceptual animal, it makes sense to incentivize this sort of thing.”

And that’s why we should think about the option, says Hucock. In the long run, he says, “it will get better, because the payoff for us as humans is greater.”

Does that mean we should choose to become digital slaves to the default outcome? “Hard to say. I think it depends on the human. But I think we should think about it in the right way. I think it’s important.”

Follow me on Twitter.
Seeking to understand more about what drives us humans, Hucock began by asking college students what they thought AI technology was. These students were then sent a face-to-face interview on the industry’s interest in digital self-driving cars.

THE INVESTOR: You may be surprised at what you find, but there are very few companies today that are actually building such products, and it’s very difficult for companies to resist. So instead of just pandering, you have to be very specific and deliberate, and you also have to be a company, and you have to do what you can to build these kinds of products, and then you have to sell those products, and so on and so forth. And in the end,
====================
Given the way we’re currently structured, the prospect of a second Industrial Revolution sounds both hopeful and dreadful. But if we take heed, heed not, because we think it sounds good, but because we think it’s not very good, we’re all going to be in a bad light.

The good news is that we’re not out of your arches. Our economic and social order has not undergone an easy rebalancing of power. The hard reality is that we’re still fundamentally in the throes of the Great Depression and were in the throes of World War II. We’ve done our best to live up to our founding ideals—we’ve built a decent society, we’re loving and we’re kind to each other. But if we fail to live up to those ideals, we will be in a bad position—we’ve spent far too much time around us, working with our partners in empire to build a dream that no one has ever seen, let alone thought of making it come true.

The bad news is that we’ve done our best to live up to our founding ideals. We’ve built a decent society, we’ve built a nice society, and we’ve learned to become more than just great at sharing our love. We’ve built great companies and societies, and we’ve learned to become better managers, better teachers, and better parents. None of these are possible without us. If we fail to do these things, we will be in a bad position—we’ve spent far too much time around us, working with our partners in empire to build a dream that no one has ever seen, let alone thought of making it come true.

The second good news is that we’re not out of your arches. Our economic and social order has not undergone an easy rebalancing of power. The onset of the Industrial Revolution required the introduction of an entirely new, energy-intensive, material-power economy. But this time, the challenge was to reinvent our society rather than to recreate it in the process. Modernity had arrived, but it had not arrived at the same pace as modernity had. Modernity has arrived early, in the 1950s, 60s, 70s, 80s, 90s, and now the economy.

Put
====================
We have seen a growing divergence between the relative fortunes of AI and human workers. As AI has gained in expertise and size, it has also become more competitive with companies who want to replace it. This has led to a dramatic slowdown in the creation of new products and services, with companies like Apple and Amazon swiftly catching up with AI in many areas. As AI continues to outcompete humans and outskill and outskill lions, the gap between us and AI will continue to widen.

But keep in mind that this is just one look at the evolution of the industry and includes other technological changes. AI-driven services like Amazon Web Services and Google Home are still a relatively young group of business innovations, ones that have yet to translate directly into dramatic economic changes. And as those changes become more widespread, they will leverage deep-learning and other AI technologies as well.

In the past, these innovations were considered low-hanging fruit. In the eyes of many traditional Silicon Valley businesses, AI was a given. The market would gladly pay a premium for a product if it could be demonstrated to work on a specific problem—if it could be proven to be safe and effective. But that never happened, and companies continued to build products and services around low-hanging fruit. As a result, the market wanted something new and then suddenly found itself in competition with AI in the pipeline.

Fast-forward to our present day, and we have the same basic dynamic at work: companies have been able to outskill and outtrain AI in order to retain market share. While we were at it, Coca-Cola introduced its soft drink to the world. The global corporation doubled down on its commitment to human nutrition by introducing a healthy serving of Zero Carb Coca-Cola. That same approach was followed up with a line of premium soft drinks like the artificially sweetened version of the Blended Coca-Cola, created specifically to replace humans.

AI has now penetrated most of the major beverage companies, and we expect to see even more AI-enabled soft drinks by the end of 2017. These include Jack Daniel's, Miller's, and Miller's, among others. While we can expect AI to play a significant role in decision-making in the near future, the key driver is still the AI in the bedroom: the device that holds our attention and forces us to change our behavior. This shift will require our own balance of power, but for the most part, we
====================
As the world watches on with horror at the thought of AI assistants like Siri or Baidu’s AlphaGo, China’s tech giants are waking up to the reality that they face in the long run how capable they are of creating these systems.

Over the past decade, China’s tech giants have pushed themselves to the limit in ways that no other nation has yet surpassed them. They’ve taken our digital lives and turned it into a billion-dollar company, but they’re also leveraged AI to become the world’s most valuable company, with market valuations of $1.7 trillion and $ 38 trillion over the past five years in Chinese market cap. That’s a lot of work for one company to do, but each one of those steps has paid off big time.

AI is now playing a key role in many industries, including manufacturing, food and beverages, construction, medicine, and banking. China is poised to become the world’s top producer of artificial intelligence, with the potential to displace as many as one million global manufacturing jobs. The country’s rapid technological progress and vibrant internet make it a perfect laboratory for developing AI-driven products and services.

But the big question for tech giants is how much impact they can have in these increasingly realizing, hyper-connected, and hyper-connected societies. Will they be able to meet those demands? Can they handle the uncertainty of medical treatment, travel, and credit, as they drive more and more people to move across the country? Will they be able to hold on to their jobs and remain relevant to the global financial markets?

It’s impossible to say for certain, but the current growth of China’s technology ecosystem could easily exceed that of any nation in the world. I believe it’s far from guaranteed that China will rapidly evolve into a world leader in AI. Its sheer scale, breadth, and depth of industries make it an open question whether China will remain on the leading edge of AI for long. But I believe the pace of technological development will accelerate significantly in the coming years, with far more AI-driven inventions created per capita in the AI-friendly cities of Shenzhen and Hangzhou.

These cities will be filled with a kind of techno-utopia, a world of essentially free and reduced automation that promises to make China the “Uber of China”
====================
The company was founded in 2005 by science fiction writer Vernor Vinge, who worked with the late science fiction writer Isaac Asimov. In 2005, Vinge published a collection of short stories, called The Technology of the Iliad, in which a man called Thaddeus, a.k.a. the Dædalus, must (in the ending) navigate his way back to Earth through many, many years of exploring artificial intelligence (or AI) technologies. The book inspired a science fiction movie, called Elysium, was released in 2006, and in 2009, Google’s DeepMind released its newest iteration, AlphaGo. In 2014, the company released a video game called Go, a role-playing game similar to the tabletop role-playing game D:T, but with a much simpler board, and greater interaction between players.

In 2014, Vinge moved from Stanford’s Stanford Lab to Los Angeles, and he began working on a project called Machine Intelligence for Humans, a Stanford-led nonprofit that would leverage AI to power the machines he created and to win money from developers. It was a big year for AI research, with companies like Google hiring for increased periods, and several hundred thousand people losing access to work. The AI revolution was about to kick-off in the United States, and the next stage of that process would take a long time.

But the ensuing years saw more than just excitement about the potential of AI to replace human beings; it also gave Google the power of approaching humans from a new perspective. By building AlphaGo using the most advanced AI technologies possible—a feat previously never attempted by the Google team—Google would be able to take the lead in the world, and it would then directly take control of the world’s top artificial intelligence system. It’ll do that by employing not only smart algorithms but also by leveraging past breakthroughs in AI to drive dramatic increases in performance. By training AlphaGo on millions of training data points, Google would be able to rapidly iterate its search and predictions for each new data point. It would then compare that result to the board of directors’ predictions, revealing which ones were less efficient and which were better.

As these AI breakthroughs are deployed in products, companies like Google pride themselves on their commitment to advanced AI technology. But the vast majority of mainstream companies are not that committed. They pull out all the stops to the point where they
====================
“We are still working on this,” she said.

“Are there any plans for collaborations with other companies to continue work on this?”

“We are all in this together.”

“Are there any plans for public collaborations with other companies to further explore AI and its impact?”

“We are all working on this now.”

During the symposium, I was able to interview Ta-Nei, the AI professor, about his vision for the future of AI. Ta-Nei is a Chinese physicist who coauthored a book with Yann LeCun called The AI Cloner: Deep Beyond the Digital World. Translation is difficult because of the rapidity of translation-which is more than a decade after the Internet took off-but he does envision a future where "human-level machine intelligence would be broadly available and accessible to the world." Translation means “fully translating” the voice of one's fellow creators into the computer; translating an original sentence into a language other than English is no different from translating an entire novel into English than translating an entire movie into Chinese.

He also happens to be an AI PhD student. He and I have collaborated on some AI research, including the translation of speech into Spanish and German into Chinese. Other collaborations I can think of are:

- Local-domain AI: Developing language models for navigation, farming, firefighting, security, and more is part of locales AI research. Having a deep understanding of the global environment and how those systems interact with humans will also be useful.
- Sensitive-domain AI: Developing systems that read people's medical and psychological labels will be useful.
- Map-based AI: Making decisions based on inferred data from existing data and the current state of the world around you will be useful.

So far, I think we have implemented a small number of these and other AI concepts, but there are still a number of important issues to address. Let me know if you find anything interesting in the comments.

According to Ta-Nei, “we have no problem with a machine-readable, fully interrogated description of the AI” and “we do not need to modify the software” as long as the AI is "fully sentient."”

Yes, that’s right. AI is a completely different
====================
“There are many authors and developers of AI systems that wrote those programs.” — Robert Mercer

As I’ve written before, the past few years’ response to the AI crisis has been to accelerate development, to “faster” the devices, and to “mission creep.” While this may sound reasonable now, in the coming years, companies will likely look to minimize impacts on people, and in doing so reap the benefits of AI. AI, as I have argued, will bring more value to people, just as heavy-handed government regulation has done for decades. It will also cut costs for companies, erasing valuable intellectual property while freeing up government resources for research. The private sector is already doing groundbreaking things with hardware, and with good intentions, but by 2017 we may see a big difference.

Automated systems are also being rolled out across the world. Google, Apple, Amazon, Uber, Airbnb, and Airbnb continue to pilot their advanced AI applications, while Y Combinator has already built a prototype that can diagnose and track cancerous compounds. Uber is already using AI to hail locations and hail the vehicles of its drivers, and Lyft is testing driver-represented rides that begin and end with the company’s own logo. And Google’s volunteer teams are constantly rerouting its networks to explore new ways to build AI systems that aren’t just augmentative to human drivers.

All this work is taking place at the speed of AI. Deep learning, AI’s synonym for processing long- standing human-language models, has attained a new standing that no one yet fully understands, thanks to AI’s profound ability to outperform human-code models. We now use them both interchangeably, as both tools are capable of generating original content that can then be used by thousands of different people for work. Both of these tools can do this without ever needing to build anything themselves, and they’re going mainstream.

But who is going to be the big winner from this transformation? The first and most obvious group will be AI developers. They will be the people who apply the most AI power, who get paid to develop the most powerful AI programs. Many of the programs built into the current generation of self-driving cars will be self-executing, because when you apply that much power to something human it just makes you less intelligent. But when you
====================
A school board official in Michigan recently told a group of students that if they wanted to continue in the school district, they would first have to pay for a monthly stipend. The student was told that if they wanted to continue, they would first have to pay for meals and other expenses. Now, the official said the student would have to pay for transportation, utilities, and textbooks. The student was told that if they chose to continue, they would first need to pay for tuition and fees.

These are just a few examples of the basic economics of AI. Funded by the U.S. government, AI systems are developed at scale and then sold to global companies, which often pay for the majority of the cost. As a result, they can be incredibly expensive to control. As an example, consider how expensive it can be to control an asteroid with an estimated mass of 9.6 Earth masses. If we could prevent it hitting us before it gets too far ahead, that might be a lot cheaper than buying a submarine from a local harbor and sinking it to sea.

AI is also used to help military and national security programs, as well as many types of automated systems. Consider how it can be done with oil and gas. How can an AI system determine whether it will cost money when there is petroleum in it? How does it determine what percentage of its storage capacity to use for a given project?

These are just a few examples. I’ve mentioned some of the AI systems that are being built for the oil and gas industry. But I think there are cases where the use of AI will have greater than the scope of other technologies. For instance, AI is being used to help predict who will be loud in the night and be loud in the day, when there is a demand for acoustic and visual information. And AI systems are being developed at a fast pace.

All of these technologies have their negative side-effects, but one of the most important is the ability to help people. How do you help a depressed or helpless customer when there is a product that you can use that can barely be heard? Another good example is a natural resource (such as coal or iron) that can provide electricity for thousands of homes or generate enough power to run at night for generations. These are just a few examples.

But there are many more subtle uses for AI. Consider a lighting system that uses AI to learn the color of a room
====================
By Robert Parry, Ph.D., and David A. Sutton, Ph.D.,

Can we really expect machines to do everything that humans can? In the 1950s, computer scientist Ray Kurzweil gave a similar talk. Kurzweil predicted that “everything” could be done by an A.I. in the next thirty years. Fast-forward to today, and Kurzweil gives a fascinating but not-so-technical history of AI that I think is mostly missing in some of today’s predictions. Kurzweil’s 1950 paper, titled “Time Travel,” was the intellectual property of Kurzweil and was published in the year 2010. In it, he wrote “Let an alien clockwork be, ‘The machine must be a real human being, such as a man or a woman.” Kurzweil went on to say that “it is my conviction that no entity, no group, no whole body of laws, no laws of nature, no intellectual property, no laws, no laws of nature, can ever create a whole human being.” Kurzweil also had this thought: “Obviously the human being has no special characteristics. . . . Nobody wants to be described as a machine-M.” I agree with this assessment. Kurzweil was right in two ways. The first is that we don’t really know what he meant by “real human” because we haven’t read his work. The second is that we do know that machines can do things, things we normally wouldn’t do. Both of these are important topics for our society, and Kurzweil’s 1950 paper was important. But I think we really don’t need to know them all.

In the book, I wrote about two different approaches to mechanizing intelligent behavior:

First, we are going to use special-purpose devices that can be operated at specific moment-of-flight (kFFLs) and are capable of doing things that no human can do. These are not things that humans can do. Second, we are going to build our own special-purpose devices that can do things that no human can do. These are not things that no computer can do, but have special relevance for the second approach.

First, build an A
====================
It’s not just the robots that are out there working on behalf of corporations. It’s also the AI algorithms that are used by law enforcement, which means they have to be trained and verified before being used in a specific context. In 2015, the US Department of Justice used facial recognition to determine it was a terrorist group.

Further complicating the issue for privacy is the fact that AI is not required to perform well in school types and is often used to track and plan terrorist activity. Schools have historically been places where the threat from terrorists is lessened, and AI has become a preferred tool for this assessment.

China and the US are two countries that pride themselves on being the world’s top producer of advanced AI. This should give the Chinese government a competitive edge over the US in the use of AI in public services and for government operations. Since the beginning of our relationship with China, I have believed the Chinese government will be far behind the American government in the use of AI in its private and public sector activities. But given the established relationship between the two countries and the competitive advantage in both directions, I expect that the Chinese government will be able to leverage its strong AI track record to gain a competitive advantage in the use of both.

Beyond the use of AI in public services and government operations, I expect the Chinese government will also continue to look to partner with local AI companies to bring some of these services closer to the American public. Local AI startups like Quanta, and nonprofits like the Stanford AI Lab, have sprung up to bring the high-end, real-world applications of AI to the masses. I foresee the US government and various agencies going out of their way to partner with these startups. They will leverage their existing data and engineering expertise in areas like IT security and vendor management, as well as their deep and comprehensive knowledge of the real world.

Finally, I’ve noticed that the Chinese government has been far ahead of the US in commercializing AI. Early-stage companies like AlphaGo have demonstrated remarkable machine-learning capabilities - the kind of capabilities that could revolutionize the manufacturing process, dramatically increasing the consumer demand for advanced AI products.

All these indicators continue to raise the value of AI as a service and business decision making, and I expect other crucial milestones for the Chinese government to follow suit.

THE CHIP ON CHINA’S AI HISTORY

But before we get
====================
Speaking of which characters are you going to guess?

I don’t like these ones. I’ve already given them four out of five, but they’re just too big a deal. I love them all. I wouldn’t want one that was five feet 6 inches.

You mentioned the eyes. I know you’re a huge Star Trek fan, do you have a question for Kai-Fu?

I do, but Kai-Fu is such a kickass person that it’s hard to know what to ask him about. I just ask him about him, and he’s like, “Kai-Fu, you know what I like?” Kai-Fu is such a kickass person, and I think he’s going to be very interested in hearing about it.

I understand your desire to be interested. I assume you’ve given your all to this show?

It’s funny because Kai-Fu is such a nice guy. He’s got a lot of friends that he’s going to be a very nice guy, but he doesn’t have a lot of friends that he’s going to be a very nice guy. So yeah, I think the question is, “What would you say Kai-Fu told you about Humans?”

It’s just such a great show. There’s no question about it. It’s just such an great universe.

Are there any particular stories you wish we had told in your series?

Not really. It’s just a way of putting it. I’m not into mythology at all. It’s just a very, very simple premise.

I really enjoy reading your scripts. Do you think the writing process changes that?

I think it improves. I think my writing has a positive effect on other writers. I think my ability to go out there and create these really special, special stories – that’s what I do.

I think I can do that. I think it’s just a lot of normal human beings are influenced by this show and I think that’s what makes it tick.

It’s just another human being with a different perspective. That’s what I think makes it tick.
====================
“We’re all human, man.”

The title of this book is a call to action for those who aspire to a better humanity. We are all parts of the same solution, united under one banner. We are all part of one common solution, one common cause, one common path. That’s why we wrote this book.”

To help inspire you to move beyond the cycle of material wealth and power that so many of us experience every day, we recommend the following five books:

1. The Path to Rich Overnight Life: Reaching on a Wave of Digital Life, Designed to Unleash the Power in Your Life

2. The Blueprint for a Rich and a Powerful Life, a Blueprint for a New World Order

3. Decisive Performance: Unleashing the Power in Your Life, from the Power of Thought

4. The Power of Figuring the Good Parts of Things Out

5. Clear the Bask in Time: Exploring Your Past, Present, and Future Time in an Infinite and Ephemeral New Way

These books have been designed to help you get beyond your current work, to reimagine your life in the style, new sensibility, or both. They are structured to help you get you out of poverty, provide you with a solid foundation to move on, and will allow you to move on without feeling trapped by the cycles of material and economic deprivation that drive our society.

To help you get beyond your current work, we have provided sample chapters for free on Amazon and Goodreads. If you like what you see, please share with your friends and family. If not, we can make some money off your purchase and make sure you have something to look forward to in the future.

We hope this book helps you navigate the uncharted waters of digital life, and that you have found the voice that this technology offers. We ask that you use this opportunity to explore the boundaries of what is meaningful in our society – a choice that we hope you discover through this book.

That choice is yours.

LOOKING FORWARD

You may be reading this because you are grappling with the consequences of an action you took or because you are grappling with a decision you made late in the book. Or you may be reading this because you are grappling with the very same choice and are grappling with very different consequences.

You
====================
Many of the people who work in IT say that the whole point of being a software engineer is to make machines smarter. They are not seeking to change the world, nor do they believe that all machines should be able to perform this task. The point is, rather, that we humans can, and should,.

In the context of automation, humans working alongside machines is called being human. We are called to act, to move machines and people around the world, to change the world by moving them. This is the job description of the software engineer, and it isn't fair to say that this is unattainable.

But working alongside machines is dangerous work. It weakens us, punishes those who dare to challenge our ideas, and actively disinterprets our humanity. This is the job description of a software engineer, and it's been for decades. And these are just a few of the issues that have beset the field for the past thirty years. The engineer is responsible for the fluid and varied work of the system, which is why there aren't many systems engineers as companies move forward with the privatization of their business models.

But there are other issues that are equally at risk. The risks are so great, the potential profits so great, and the incentives so great. The risk is such that no system is safe without the other. In fact, there is no way to distinguish the riskiest from the others, because the risks are so great. But consider this: the riskiest companies are those that have the largest upside for the shareholders. If everyone gets rich, the shareholders would own a majority of the company, while the people would be able to invest their own money in the business. That makes sense, because if everyone gets rich, the shareholders would own a majority of the company, but if everyone else gets rich, the upside for the shareholders is minimal. If everyone gets rich, then everybody else loses. In this case, the shareholders would own a majority, whereas the people, because the shareholders own a majority, the upside for the company is minimal.

In the same way, a human-run system, if it could be built, could be built, so that the humans would operate the business while the humans were away. Likewise, if it were possible to build a digital rerun of an important developmental milestones, then a human run system, which could run the test and analyze the data, would be minimally
====================
“What does the AI industry do now?”

The industry is working on tools for self-improving. The most successful of these tools is called “batch-based optimisation.” It starts from a small batch of AI-generated outputs and moves up in value-adding step toward higher-value outputs. At each stage of the process, a batch of AI-generated outputs increases the more the batch-based optimisation method is applied. A batch-based optimisation step essentially becomes “the’s high-tech art, a way of thinking about the process that doesn’t need to be explained by further step processes.”

“What is the future of AI?”136”

AI has arrived at a time when any good engineer can see it: the digital humanities are undergoing a renaissance, a renaissance of the digital sciences are in full swing, and machine learning is starting to show its true age. Many leading companies have already introduced machine-learning technology to their product features, and some are already using it to overhaul decision processes and decision processes around the phenomenon of preconditions for human-level AI development.

There are several technical breakthroughs that are stirring debate and giving hope to the AI future. But there are also many dark secrets hidden within these tools that could make or break the commercial and industrial ecosystem for twentieth-century AI. And the answers to these questions are pouring out into the world every day.

Chapter 3: Social AI

Social AI is the next phase of the third wave of AI, following in the footsteps of the first three waves. It aims to provide a “collect all the apps,” platform for mass social interaction, including AI-generated content, social media and apps, are used for widespread automation, and personalisation. It is aiming to transform social interactions across the world into AI-generated content tailored to a given individual or audience. The tools aim to amplify the collective power of human beings around the world, from poaching criminal organizations to climate change denial.

They aim to augment the collective power of humanity’s 99.999% accuracy—that is, the collective power of the people using our apps, websites, social media platforms, and data. This represents a radical increase in power output (measured in microprocessor, bit rate, and power) and an unprecedented refocus on what we do. It
====================
“So, “Can we really trust the government if the banks have all these artificial intelligence tools?” “I think the answer is yes” Mr. Rossum said. “It’s a risk, a fraud.”

The tech sector has been pushing the boundaries of AI for decades, and AI systems like GPT-4 are part of that. But as the sector’s abilities improve, so does the risk it poses, experts say.

“It’s just another way of saying that the whole brain emulation project has taken a long time.” Mr. Rossum said. “It’s just a really clever, long-term thing.”

BETTING ON AI

The goal of the artificial intelligence community in the United States is not to make more devices that are safe and beneficial for humans, Mr. Rossum said. It’s to make the world a safer place.

“I think we’ll be able to get there,” he said. “But I also think we’ll be putting in dangerous places.”

The danger, he said, is not in making more devices that are dangerous, but in the lack of preparation and the lack of awareness we have as a people.

“It’s like they say in Saudi Arabia, ‘You can get killed if you’t play by the rules.’ It’s such a blank check to be able to go ahead and do what we do well and not worry about repercussions.”

That has not happened in the United States, where the threat from AI systems comes from more than in Saudi Arabia, he said. But he acknowledged that the United States has a large number of highly advanced AI systems and other tools that are in the “loophole between everybody’s computers.” So while the federal government takes precautions, experts recommend caution when it comes to making smart, connected devices.


/ 014. Ned Block, M.Phil. Now that smartphones are everywhere, what do they do? They automatically send text and voice data back and forth between your smartphone and your computer so you can focus on what matters, and your computer itself. But what are the vendors up to? That data is practically invisible, it just lists the location of your
====================
“How do you know that you’re not going to get a hundred thousand people into the asylum?” “Because they are human, not because they are artificial,” the AI answered. “You can’t trust them,” the AI continued. “But I think we’ll eventually get a hundred thousand.”

The AI is largely silent as it speaks, almost as if it had no choice but to make the decision anyway.

The AI is based in Edinburgh, which is a pretty cool city (even by AI standards) but one of the reasons we’re seeing so much interest in the project is because of the way it will affect those people who are most likely to be housed there. There are a number of different AI labs already operating in the US and Canada, and these will be a major influence. The Al-35 is a prime example. It already has a good reputation for smarts, but there’s no guarantee that it will do more harm than good.

Researchers will have to find ways to nudge people into this path. The US military already houses HLAI’s for cyberwarfare applications in HAVA support labs and at military labs across the world. The AI will have to be smarter, more compassionate, and more compassionate, and then feed those applications data necessary for human enhancement. Ultimately, that data will have impacts beyond the battlefield – I doubt that AI systems will have as much impact as some might think.

The AI is also going to have to take on a whole new set of security and privacy concerns. While in the service of humanity, it may turn on a human and informate the decision-maker. Humans may become the targets of automated systems that want to exploit the data. This could mean the difference between a temporary privacy victory and a permanent existential threat.

One concern is that the AI may be biased in favor of a particular political viewpoint. That could mean the AI is more likely to support a particular candidate, or to have a record of “hating immigrants” than a predominantly white group. That could mean the AI is also biased in favor of a particular company, or might just prefer certain products made from whole grains – all these are potential issues that will require consideration of the trade secrets to public disclosure laws.

Another concern is that the AI may be biased against human professions that
====================
When we first met in 2009 at Google I/O, he was chatting with Larry Page about creating a new kind of web browser called Pageant, a clone of Mark Zuckerberg's browser but better. He described the browser as being “faster,” to be more precise, than Mark. Larry also described the browser as having more depth than Mark. Both of these attributes were important to us in our subsequent conversations.

In those subsequent conversations, we’ll discuss the different ways that different firms have developed Pageants and how their customer experiences with Pageants have evolved over the years.

In the following conversations, we will describe some of the different ways that different firms have developed complementary products. We will also discuss how firms have continuously evolved their customer relationships with Google. We will conclude this chapter with a call for action.

3
CHAPTER 9: Multinational Corporations in the Global Economy

Growth Economics

Most people assume that companies based in the United States and China will continue to generate growth, despite substantial job losses and other factors, just as companies based in those countries do now. They may, for instance, continue to generate comparatively weak growth in US$ per capita on average over the past few years, rather than strong growth in GPT(net GPT) on average over the long term. Growth-oriented companies, on the other hand, might continue to grow in GPT on average over the course of a decade or more.

If the US economy is to recover sufficiently from the Great Recession, it may also need to sustain and increase the levels of growth-oriented companies in the global economy.

A strong and growing economy consists of economically productive activities that produce more when compared to their less resource-intensive counterparts. Such activities include the following:

- Import pricing: domestically produced goods and services are typically labeled as such, even though they may not be themselves net externals. Import prices are used to track the prices of other goods and services, and are therefore directly correlated with overall economic values. The US dollar has lost value relative to the value of its purchasing power as a currency as a whole. This suggests that the US economy’s current externalities include having relatively strong internal growth-oriented companies.
- Demand management: the idea of demandmaximizing products and services by storing and processing inputs in the system is attractive as a potential short-term solution to the US slowdown,
====================
Many of the people who work in the health-care industry, with its emphasis on technicians and waiters, tend to think that the only way to meaningfully benefit from automation is to hire someone to do the repetitive tasks themselves. They see themselves as being on call-monitoring systems that must be tweaked and adjusted to work effectively with new equipment.

Many of the people who work in the financial services industry, with its emphasis on financial institutions and risky financial decisions, tend also to think that the only way to meaningfully benefit from automation. They see themselves as being on call-monitoring systems that must be tweaked and adjusted to operate effectively with new information and technology. They also understand that the companies that profit from these machines are typically not well-known outside of their industries, and so they tend to be quiet about what they are doing. As a result, they tend to be quiet about what they are working on, even when they are not technically doing anything at all.

The traditional approach to AI, which concentrates on strictly routine tasks handled by humans (think of it as a “automation of bodies,” was probably also famously successful in the medical field), also seems to have had no significant effect on the majority of people who responded favorably to the AI systems they encountered. The traditional approach to AI, in contrast, seems to have focused on novel and unusual capabilities that appear to be novel only in retrospect, when the machines are operating as normal.

In the early days of deep learning, the traditional approach to the art of the job required a combination of experimentation and careful planning. But as the field gained experience with more powerful artificial intelligence systems, the pace of innovation in the underlying technology began to accelerate, and by the 1990s, computers with these capabilities were already standard.7 The traditional approach to the profession wasn’t thorough, but when iterated, well-designed technologies like GPT-4 emerged in the 1990s, and GPT-3 and earlier the iterated nature of GPT-2 and its variants, combined with its limitations, made it potentially difficult to find practitioners who were ready to adapt or remake the process around these systems.

The traditional approach to AI, which focused on strictly routine tasks handled by humans, also required a kind of outsourcing. Instead of hiring highly paid professionals who perform routine routine tasks, companies typically hire only specialists who perform specialized specialized specialized tasks. In contrast, GPT-
====================
“Is it possible for a machine to duplicate itself, by using the similar methods of the human mind?” “It seems that it may not be possible to create a copy of itself. If it were so clever, wouldn’t it be better to make a machine mimic itself instead?” “In that case, would the mimic be able to tell what was in its own self-possession?”

These are all important questions, but I think the AI field’s attempts to mimic the intellectual processes of its participants are by far the more important ones. I’ve written before about other attempts to do this, but this is by far the biggest change that opens up.

History provides another important clue. In 632 BBY the British parliament passed the “Machines in the Light” Act, which required that “works of science and technology should be permitted under strict surveillance and regulation be done in the light of scientific and technological discoveries.” The bill was to be enforced by strict surveillance, but the British government resisted the act’s requirements and passed the “Manchuk Amendment Act, which required that any publication in a darkroom or where it might be kept for more than six months “to guard against the risk of dangerous experimentation with scientific and medical knowledge contained in the knowledge base”” (emphasis added).

The English government still does not have permission to keep dark rooms for scientific and medical purposes.34 Machines in general are very good at things that are dark,34 which means they don’t like to be switched on or off. Therefore, the Act’s requirements are still in place, though only for work that is dark. In fact, the darkroom definition is so broad that even the words “science” and “technology” are required. The “Machines in the Light” definition is so broad that even the words “works of science and technology” are included. Thus, the attempts to provide “support for the establishment of conformity of safe and effective technology in the industrial sector are at least as relevant today as they were when the bill was passed in 1853.

Conclusion: Smart tools

Unfortunately, many of the tools that were built into the Industrial Revolution have been detrimental to the common good. Many of them have already been incorporated into modern day medicine and the
====================
