OUTPUT 012							AUTOMATA - GPT-2						 EPOCHS : 14000



How AI is Replacing the Human Mind

The third major transformation involves the reimagining of business processes by reimagining them from an alien third person. This third era, which builds on the earlier practices of tech-based outsourcing, will be more dramatic than the earlier infrastructures and will require far more fundamental resets to rethink business processes.

Back in 1999, two years before the computer science breakthroughs that Summers speaks of, I was still a little less optimistic. Two years later, four years before that academic paper and four years before the development of deep learning. Since then, the amount of work in AI has increased; the answer to a market-driven market is unknown.

For years, the most I could think about these new jobs was to be a laborer, to be a burden on the factory floor, to be paid pennies per hour in additional effort. I believed that given the dizzying profits that Musk predicts, I would be hard-pressed to find a job in a Musk-esque company.

In reality, I was imagining a life of food delivery, a good night’s sleep, and a great night’s meal. To be clear, I was not asking whether a job could be done in the real world. Companies like Tesla and Amazon are offering to pay only the minimum wage, a living wage at a time when the vast majority of humans are paid below the poverty line. In the absence of widespread job verification and a guaranteed income, many workers will be forced to move out of livelihood and permanently cut off from the economy.

Will we by then have constructed a social order that will preclude the taking of as yet undiscovered physical phenomena altogether? Will there be economic or social disruption if we don’t know how?

These are concerns that have engaged both computer scientists and humanists. In 1987 Jack Schwartz wrote that many humanist thinkers

. . . express the amorphous unease of a much broader public. The fear is that the whole fabric of human society, which at times seems terrifyingly fragile, may be torn apart by enormously rapid technological changes set in motion by AI research as it begins to yield its major fruits. For example, it is possible to imagine that would-be dictators, small centrally placed oligarchies, or predatory nations could exploit this technology to establish a power over society resting on robot armies and police forces independent of extensive human participation and entirely indifferent to all traditional human or humane considerations. Even setting this nightmare aside, one can fear a variety of more subtle deleterious impacts, for example, rapid collapse of human society into a self-destructive pure hedonism once all pressures, and perhaps even reasons or opportunities, for work and striving are undermined by the presence of unchallengeably omnicompetent mechanisms. Certainly man’s remaining sense of his own uniqueness may be further impaired, and he may come to seem in his own eyes little more than a primitive animal, capable only of fleeting enjoyments.

To confront these fears, Stephen M. Omohundro (1959– ), an AI researcher, founded Self-Aware Systems, an organization “devoted to bringing wisdom into emerging technologies.”51 He thinks “we must be very careful” about developing AI systems. That’s because they will have, by design, various goals and drives. Among these are the goals to be self-improving and rational. They will attempt to accomplish these goals and the goals given to them by humans in the most effective manner possible. To be maximally effective they will have drives to preserve themselves and to acquire resources. These characteristics remind us of HAL 9000, the robot on the spaceship in the book and movie 2001: A Space Odyssey. Omohundro wants to make sure that we build “wisdom,” and not just intelligence, into our technologies. By that he means building in “human values, such as caring about human rights and property rights and having compassion for other entities.” He thinks it “absolutely critical that we build these in at the beginning, otherwise we’ll get systems that are very powerful, but which do not support our values.” I think Omohundro brings up valid concerns, but to put his version of wisdom into AI systems we’ll first have to agree on just what we mean by “human values.” That will be tough given that our different opinions about values often lead to wars.

After many years working on mobile robotics, Professor Ronald Arkin (1949– ) of the Georgia Institute of Technology has devoted attention to the problem of ethical issues surrounding the use of military robots. His book Governing Lethal Behavior in Autonomous Robots explores how to program an “artificial conscience” in robots.53 He maintains that such robots might behave more ethically in the battlefield than humans currently can. Of course many people believe that even being on a battlefield is
====================
The tool-AI that powers this AI revolution is central to how the third wave of business process transformation is shaping the future of work. Work is central to Kroc’s argument, but it’s also a salient source of personal transformation in the post-transition economy.

The commercial AI revolution is not coming; it is already here, and it is about far greater things than the abstract promises of artificial intelligence. The potential economic and social benefits of AI are vast, including perhaps the greatest potential to expand human sales and profitably impact all workers. Indeed, the United States has already made several examples of how beneficial it is to produce goods and services using AI. For example, the state of California enacted a law in 2015 that requires all new vehicles to have a programmed AI system by 2020.1 It’s a compelling and necessary explanation of how governments can meaningfully impact the widespread use of AI in these areas.

Yet we have seen little in the way of practical progress in the way of implementation. The US government has still not announced how many AI systems will be on the market by 2020, and companies like Nvidia, Salesforce, and Adobe are already legally obligated to act on the widespread misconception that there is a single AI system.2 It is important that we not gratuitously replicate such failures of government overreach.

If we are to make a difference, then we must be willing to taking extreme steps. The next step is to prepare for the worst-case scenarios. These include taking military-level covert action in the developing world and seducing corporate AI via hardware or software. We cannot postpone confronting this challenge or give ourselves the luxury of being able to match superhuman artificial intelligence in the closely related service professions.


/ 017. Crawford, Kate. Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence, 2021.

What is AI? Neither Artificial nor Intelligent

Let’s ask the deceptively simple question, What is artificial intelligence? If you ask someone in the street, they might mention Apple’s Siri, Amazon’s cloud service, Tesla’s cars, or Google’s search algorithm. If you ask experts in deep learning, they might give you a technical response about how neural nets are organized into dozens of layers that receive labeled data, are assigned weights and thresholds, and can classify data in ways that cannot yet be fully explained.16 In 1978, when discussing expert systems, Professor Donald Michie described AI as knowledge refining, where “a reliability and competence of codification can be produced which far surpasses the highest level that the unaided human expert has ever, perhaps even could ever, attain.”17 In one of the most popular textbooks on the subject, Stuart Russell and Peter Norvig state that AI is the attempt to understand and build intelligent entities. “Intelligence is concerned mainly with rational action,” they claim. “Ideally, an intelligent agent takes the best possible action in a situation.”

"Each way of defining artificial intelligence is doing work, setting a frame for how it will be understood, measured, valued, and governed. If AI is defined by consumer brands for corporate infrastructure, then marketing and advertising have" "predetermined the horizon. If AI systems are seen as more re- liable or rational than any human expert, able to take the “best possible action,” then it suggests that they should be trusted to make high-stakes decisions in health, education, and criminal justice. When specific algorithmic techniques are the sole focus, it suggests that only continual technical progress matters, with no consideration of the computational cost of those approaches and their far-reaching impacts on a planet under strain."

"In contrast, in this book I argue that AI is neither artificial nor intelligent. Rather, artificial intelligence is both embodied and material, made from natural resources, fuel, human labor, infrastructures, logistics, histories, and classifications. AI systems are not autonomous, rational, or able to discern anything without extensive, computationally intensive training with large datasets or predefined rules and rewards. In fact, artificial intelligence as we know it depends entirely on a much wider set of political and social structures. And due to the capital required to build AI at scale and the ways of seeing that it optimizes AI systems are ultimately designed to serve existing dominant interests. In this sense, artificial intelligence is a registry of power."

"In this book we’ll explore how artificial intelligence is made, in the widest sense, and the economic, political, cultural, and historical forces that shape it. Once we connect AI within these broader structures and social systems, we can es- cape the notion that artificial intelligence is a purely technical domain. At a fundamental level, AI is technical and social practices, institutions and infrastructures, politics and culture. Computational reason and embodied work are deeply interlinked: AI systems both reflect and produce social
====================

