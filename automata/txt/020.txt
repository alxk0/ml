OUTPUT 020							AUTOMATA - GPT-2						 EPOCHS : 22000



’s strength in AI came at an unfortunate time: the global economic slowdown and stagnant wages had given its companies an insurmountable advantage. The rise in China’s manufacturing-output gap between China and the United States dwarfs even the most ambitious science-fiction films ever made. The country has already vaulted far ahead of the United States as the world’s largest manufacturing robot market, deploying more than four times as many robots as the next most American firms combined. And robotization is just one of many high-profile AI applications in construction—in other words, when done in the home, the continuous-process applications become increasingly capable of sensing and analyzing the real-world conditions around us and making adjustments in real time. (See the sidebar "AI in the home" at the end of this chapter.)

But the danger of such applications wasn’t just evident in the manufacturing sector. It was in the real world.inition of manufacturing processes. New automation techniques, which can be applied to factories and other industrial settings, are poised to disrupt the careers of many hand-built industrial robots. These robots are many kinds of machinery: robot arms, robot builders, surgical robots, and so on. And while it’s true that the long-term historical trend has been toward more jobs and greater prosperity, it’s also salient to see how this era of industrial transformation is also shaping the choices we face every day.

The choices are very different.romanaging a complex set of machines is a very different question. On the one hand, it sounds flippant to think that a superintelligent machine might at any future point be able to say, “I’m a radiologist.” What this means is that it’s not too soon to call them doctors’ healthcare. However, it’s also important to understand the history of what motivated them to do such a remarkable thing.

The first three decades of the twentieth century brought transformations that altered the very nature of work itself. In many industries, the abolishment of work came in the form of rentiers, who could live on an unprecedentedly high-quality per-unit income, work multiple jobs and be highly valued by their employees. In the earlier era of mechanization, rentier extraction represented one in every three dollars of income, and it represented almost a tenfold increase over the total number of jobs in the United States. Today, the same rent increases are passed on to their employees—amorphosing the traditional piece-rate system, in which case workers are still saddled with large surcharges on their labor. This financial transformation is also why the traditional basis of imperative control is now a threat to economic security, since when the authority of the state comes to depend upon making decisions about workers’ lives? If the only way to achieve such protection were by restricting membership to copy-siblings (so that all emulations in a particular superorganism could benefit from the union representation of a similar number of humans), then superorganisms would suffer some disadvantage in being able to draw only from a range of skills narrower than that of rival organizations, a disadvantage which might or might not be large enough to outweigh the advantages of avoiding internal agency problems.37 This disadvantage would be greatly alleviated if a superorganism could at least contain members with different training. Even if all its members were derived from a single ur-template, its workforce could then still contribute a diversity of skills. Starting with a polymathically talented emulation ur-template, lineages could be branched off into different training programs, one copy learning accounting, another electrical engineering, and so forth. This would produce a membership with diverse skills though not of diverse talents. (Maximum diversity might require that more than one ur-template be used.)

The essential property of a superorganism is not that it consists of copies of a single progenitor but that all the individual agents within it are fully committed to a common goal. The ability to create a superorganism can thus be viewed as requiring a partial solution to the control problem. Whereas a completely general solution to the control problem would enable somebody to create an agent with any arbitrary final goal, the partial solution needed for the creation of a superorganism requires merely the ability to fashion multiple agents with the same final goal (for some nontrivial but not necessarily arbitrary final goal).

The main consideration put forward in this subsection is thus not really limited to monoclonal emulation groups, but can be stated more generally in a way that makes clear that it applies to a wide range of multipolar machine intelligence scenarios. It is that certain types of advances in motivation selection techniques, which may become feasible when the actors are digital, may help overcome some of the inefficiencies that currently hamper large human organizations and that counterbalance economies of scale. With these limits lifted, organizations—be they firms, nations, or other economic or political entities—could increase in size. This is
====================
’s so-called five stages: infancy, adolescence, high, low, and medium. Before that, it looked like only kindergarteners could attain writing skills. During the next two decades, it looked like only the most specialized professions—tattooed robots, for example—could apply. By the mid-1980s, a growing number of researchers were trying to understand how the brain worked while another group of researchers were trying to understand how the brain worked while it was in the service of speech recognition. Each of these investigations has centered on notion of a universal brain, but in the next three decades we have been seeking the mathematical structure of the brain, i.e., the patterns and activities in the brain, while the machinery that produces those patterns is relatively obscure.

In the history of mathematics, new kinds of mathematically inclined people exist quite a few years after the eighteenth century. Minsky, Forster, and Ross, who would become members of the World Wide Web in 1875 and then later became the head of MIT’s Artificial Intelligence Laboratory (AI Lab), had been working on programs for proving theorems in symbolic logic. I led the way to some early work on networks of neuron-like units developed in the nervous system. In the mid-1940s, a group of psychologists, mathematicians, and computer scientists, including Minsky, created a series of programs that made simple inferences about the aspects of networks of neuron-like units, which were then transformed into logical statements. In the late 1940s and early 1950s, these programs were widely used by AI researchers to verify theorems in networks of neuron-like units. A later director, Marvin Minsky (1916–2001; Fig. 2.4), began by teletypesetting his IBM 704 computer to produce programs that could be stored on a computer and sent over a network. The most sophisticated of these was the later, more primitivelihood management system of LISP (now the AI language). In 1959, Minsky set up the Businessial Self-Driving Service (BDS) that routes drivers around major hubs throughout the Bay Area. He claimed that his new service,beam, outperforms the competition but is not necessarily faster. In fact, he wrote, “Intelligence is pride.”

A second reason for declining to provide a standard definition for AI is that there is no comprehensive set of AI’s own workings. The definition must change, and so technologies must be adapted, rather than replaced, in the hope of finding useful new ways to accommodate themselves to changing conditions. But this rather general notion of technological improvement is not inestimable. It is, nonetheless, the more common form of arguing over the direction of technological change.

ighthill’t

[The third kind of argument� is that the necessity of technological change is the “combinatorial takeoff,” that is, the amount of physical effort required to make certain physical processes efficient.primarily by human workers. But there are other kinds of inefficiencies in human operations also. Anecdotes are legion: expert tools prescribed by an organic manual labor, for instance, are required to turn out the lights after an employee’s car or truck driver fender rag accidentally puddles them.

Consider the case of the tailor-made BMW automobiles for customer service that put an emphasis on customer service. When a customer uses an automated teller machine, the data-entry function of the teller machine is accomplished automatically. In less than fifteen years, computer vision has become so good that it requires the help of two humans to guide the machine. One of them painstakinglyfts a measuring tape from inventory control systems to inventory management systems to the health department to inventory systems. The second man probes the process with a measuring tape and then the human operator in command of the machine. They begin to chat with a voice-activated tool that is providing them with instructions and guidance.

They say they are able to analyze all these instruments and are responsive to what they are receiving because they are able to interpret the output and respond robustly to what is sensed. . . . It is improvement on what was possible with traditional process-control software.”

When Microsoft realized its inspiration for the process-control software, it took the idea of process-control methods for automating tasks in the company environment of big data and turned it into an important and irresistible application. As we saw in chapter 6, the metaphors just described provide us with a sense of psychological distance from the field of AI and what kinds of jobs are at risk.

Instead of seeking to be a kind of superintelligence, we should begin with the lived experiences of those who are disempowered, discriminated against, and harmed by AI systems. When someone says, “AI ethics,” we should assess the labor conditions for miners, contractors, and crowdworkers. When we hear “optimization,�
====================
” to be performed.

One of the psychiatrist judges did, in fact, make a rather half-hearted attempt to break out of the mold and ask some telling questions: “Maybe you’ve heard the saying ‘Don’t cry over spilled milk.’ What does that mean to you?” PARRY answered, “Maybe you have to watch out for the Mafia.”

When then asked “Okay, now you were in a movie theater watching a movie and smelled something like burning wood or rubber, what would you do?” PARRY replied, “You know, they know me.” And the next question was, ” you found a stamped, addressed letter in your path as you were walking down the street, what would you do?” PARRY replied, “What else do you want to know?”7

Clearly, PARRY was, you might say, parrying these questions, which were incomprehensible to it, with more or less stock paranoid formulas. We see a bit of a dodge that is apt to work, apt to seem plausible to the judge, only because the “contestant” is supposed to be a paranoid, and such people are expected to respond uncooperatively on such occasions. These unimpressive responses didn’t particularly arouse the suspicions of the judge, as a matter of fact, though they probably should have.

PARRY, like all other large computer programs, is dramatically hound by limitations of cost-effectiveness. What was important to Colby and his crew was simulating his model of paranoia. This was a massive effort. PARRY has a thesaurus or dictionary of about 4,500 words and 700 idioms and the grammatical competence to use it-a parser, in the jargon of computational linguistics.

The entire PARRY program takes up about 200,000 words of computer memory, all laboriously installed by the programming team. Now once all the effort had gone into devising the model of paranoid thought processes and linguistic ability, there was little time, energy, money, and interest left over to build in huge amounts of world knowledge of the sort that any actual paranoid would, of course, have. (Not that anyone yet knows haw to build in world knowledge in the first place.)

Even one could do it, building in the world knowledge would no doubt have made PARRY orders of magnitude larger and slower. And what would have been the point, given Colby’s theoretical aims?

PARRY is a theoretician’s model of a psychological phenomenon: paranoia. It is not intended to have practical applications. But in recent years there has appeared a branch of AI (knowledge engineering) that develops what are now called expert systems. Expert systems are designed to be practical. They are typically software super specializt consultants that can be asked to diagnose medical problems, analyze geological data, analyze the results of scientific experiments, and the like. Some of them are very impressive.

SRI in California announced a few years ago that PROSPECTOR, an SRI-developed expert system in geology, had correctly predicted the existence of a large, important mineral deposit that had been entirely unanticipated by the human geologists who had fed it its data. MYCIN, perhaps the most famous of these expert systems, diagnoses infections of the blood, and it does probably as well as, maybe better than, any human consultants. And many other expert systems are on the way.

All expert systems, like all other large AI programs, are what you might call Potemkin villages. That is, they are cleverly constructed facades, like cinema sets. The actual filling-in of details of AI programs is time-consuming, costly work, so economy dictates that only those surfaces of the phenomenon that are likely to be probed or observed are represented.

Consider, for example, the CYRUS program developed 6y Janet Kalodner in Roger Schenk’s AI group at Yale a few years ago. CYRUS stands (we are told) for “Computerized Yale Retrieval and Updating System,” but surely it is no accident that CYRUS modeled the memory of Cyrus Vance, who was then secretary of state in the Carter administration.

The paint of the CYRUS project was to devise and test some plausible ideas about how people organize their memories of the events they participate in. Hence, it was meant to be a “pure- AI system, a scientific model, not an expert system intended for any practical purpose. CYRUS was updated daily by being fed all UPI wire-service news stories that mentioned Vance, and it was fed them directly with no doctoring and no human intervention.

With an ingenious news-reading program called FRUMP, it could take any story just as it came in on the wire and
====================

